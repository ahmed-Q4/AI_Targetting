<<<<<<< HEAD
data.set2 <- data.set %>% dplyr::mutate(Position_normalized = Position/NumberHolders,
Position_percent = Position_normalized/SharesOutstanding) %>%
dplyr::group_by(Symbol) %>% dplyr::mutate(lag_Position_normalized = lag(Position_normalized),
Position_normalized_change = Position_normalized - lag_Position_normalized,
lag_Position_percent = lag(Position_percent),
Position_percent_change = Position_percent - lag_Position_percent,
lag_Position = lag(Position),
Position_change =  Position - lag_Position) %>%
dplyr::ungroup() %>%
dplyr::select(-grep(pattern = "Date_", x = names(.)), # -row_names.x, -row_names.y,
-grep(pattern = "lag_", x = names(.))) %>%
try(dplyr::select(.,-row_names.x, -row_names.y, -row_names.z))
names(data.set2)
data.set2 <- data.set %>% dplyr::mutate(Position_normalized = Position/NumberHolders,
Position_percent = Position_normalized/SharesOutstanding) %>%
dplyr::group_by(Symbol) %>% dplyr::mutate(lag_Position_normalized = lag(Position_normalized),
Position_normalized_change = Position_normalized - lag_Position_normalized,
lag_Position_percent = lag(Position_percent),
Position_percent_change = Position_percent - lag_Position_percent,
lag_Position = lag(Position),
Position_change =  Position - lag_Position) %>%
dplyr::ungroup() %>%
dplyr::select(-grep(pattern = "Date_", x = names(.)), # -row_names.x, -row_names.y,
-grep(pattern = "lag_", x = names(.))) %>%
try(dplyr::select(.,-row_names.x, -row_names.y))
names(data.set2)
data.set2 <- data.set %>% dplyr::mutate(Position_normalized = Position/NumberHolders,
Position_percent = Position_normalized/SharesOutstanding) %>%
dplyr::group_by(Symbol) %>% dplyr::mutate(lag_Position_normalized = lag(Position_normalized),
Position_normalized_change = Position_normalized - lag_Position_normalized,
lag_Position_percent = lag(Position_percent),
Position_percent_change = Position_percent - lag_Position_percent,
lag_Position = lag(Position),
Position_change =  Position - lag_Position) %>%
dplyr::ungroup() %>%
dplyr::select(-grep(pattern = "Date_", x = names(.)), # -row_names.x, -row_names.y,
-grep(pattern = "lag_", x = names(.))) %>%
try(dplyr::select(-row_names.x, -row_names.y))
names(data.set2)
data.set2 <- data.set %>% dplyr::mutate(Position_normalized = Position/NumberHolders,
Position_percent = Position_normalized/SharesOutstanding) %>%
dplyr::group_by(Symbol) %>% dplyr::mutate(lag_Position_normalized = lag(Position_normalized),
Position_normalized_change = Position_normalized - lag_Position_normalized,
lag_Position_percent = lag(Position_percent),
Position_percent_change = Position_percent - lag_Position_percent,
lag_Position = lag(Position),
Position_change =  Position - lag_Position) %>%
dplyr::ungroup() %>%
dplyr::select(-grep(pattern = "Date_", x = names(.)), -row_names.x, -row_names.y,
-grep(pattern = "lag_", x = names(.)))
names(data.set2)
data.set2 <- data.set %>% dplyr::mutate(Position_normalized = Position/NumberHolders,
Position_percent = Position_normalized/SharesOutstanding) %>%
dplyr::group_by(Symbol) %>% dplyr::mutate(lag_Position_normalized = lag(Position_normalized),
Position_normalized_change = Position_normalized - lag_Position_normalized,
lag_Position_percent = lag(Position_percent),
Position_percent_change = Position_percent - lag_Position_percent,
lag_Position = lag(Position),
Position_change =  Position - lag_Position) %>%
dplyr::ungroup() %>%
dplyr::select(-grep(pattern = "Date_", x = names(.)), #-row_names.x, -row_names.y,
-grep(pattern = "lag_", x = names(.)),
-grep(pattern = "row_names.", x = names(.)))
names(data.set2)
data.set2 <- data.set %>% dplyr::mutate(Position_normalized = Position/NumberHolders,
Position_percent = Position_normalized/SharesOutstanding) %>%
dplyr::group_by(Symbol) %>% dplyr::mutate(lag_Position_normalized = lag(Position_normalized),
Position_normalized_change = Position_normalized - lag_Position_normalized,
lag_Position_percent = lag(Position_percent),
Position_percent_change = Position_percent - lag_Position_percent,
lag_Position = lag(Position),
Position_change =  Position - lag_Position) %>%
dplyr::ungroup() %>%
dplyr::select(-grep(pattern = "Date_", x = names(.)), #-row_names.x, -row_names.y,
-grep(pattern = "lag_", x = names(.)),
-grep(pattern = "row_names..", x = names(.)))
names(data.set2)
data.set2 <- data.set %>% dplyr::mutate(Position_normalized = Position/NumberHolders,
Position_percent = Position_normalized/SharesOutstanding) %>%
dplyr::group_by(Symbol) %>% dplyr::mutate(lag_Position_normalized = lag(Position_normalized),
Position_normalized_change = Position_normalized - lag_Position_normalized,
lag_Position_percent = lag(Position_percent),
Position_percent_change = Position_percent - lag_Position_percent,
lag_Position = lag(Position),
Position_change =  Position - lag_Position) %>%
dplyr::ungroup() %>%
dplyr::select(-grep(pattern = "Date_", x = names(.)), #-row_names.x, -row_names.y,
-grep(pattern = "lag_", x = names(.)),
-grep(pattern = "roww_names.", x = names(.)))
names(data.set2)
data.set2 <- data.set %>% dplyr::mutate(Position_normalized = Position/NumberHolders,
Position_percent = Position_normalized/SharesOutstanding) %>%
dplyr::group_by(Symbol) %>% dplyr::mutate(lag_Position_normalized = lag(Position_normalized),
Position_normalized_change = Position_normalized - lag_Position_normalized,
lag_Position_percent = lag(Position_percent),
Position_percent_change = Position_percent - lag_Position_percent,
lag_Position = lag(Position),
Position_change =  Position - lag_Position) %>%
dplyr::ungroup() %>%
dplyr::select(-grep(pattern = "Date_", x = names(.)),
-grep(pattern = "lag_", x = names(.)),
-grep(pattern = "row_names.", x = names(.)))
dbWriteTable(con, "data_set", data.set2)
dbWriteTable(con, "data_set", data.set2, overwrite = TRUE)
data.set2 <- dbReadTable(con, "data_set")
data.set3 <- na.omit(data.set2)
Test_years <- c(2015)
Training_years <- c(2008:2014)
regression_data <- data.set3[,c(59,1,3,9:54)] %>%
dplyr::filter(Year %in% Training_years) %>%
dplyr::select(-Symbol, -Date, -Year)
save.image("~/R_workspaces/AI_Targetting/Workspace_01.RData")
library(HighDimOut)
getDoParWorkers()
foreach::getDoParWorkers()
foreach::getDoParWorkers()
load("~/R_workspaces/AI_Targetting/Workspace_02_RegressionReady.RData")
context_var <- c(#"Symbol", "Year",  "Date",
"HasOptions", "SharkGrouping", "NumberHolders", "SharesOutstanding", "FSPermSecId")
Y_var_potential <- grep(pattern = "Position", x = names(data.set3), value = TRUE)
Y_var <- "Position_change"
X_var <-  setdiff(names(data.set3),
union(Y_var_potential, context_var))
# Identification of Training & Testing data set ------
# Random Sample vs Specific years for training set
RANDOM_TRAINING <- FALSE
=======
<<<<<<< HEAD
=======
<<<<<<< HEAD
=======
<<<<<<< HEAD
model_tt1 <- robustbase::glmrob(Buy_Sell ~ ., family=binomial(), data = Training_data_classification)
model_tt2 <- robustbase::glmrob(Buy_Sell ~ ., family=binomial(), data = Training_data_classification, weights.on.x = "robCov")
# 3.2 Bias reduction in binomial-response generalized linear models: brglm package
# penalized likelihood where penalization is by Jeffreys invariant prior.
m_Logit_BiasRedution <- brglm::brglm(Buy_Sell ~ ., family = binomial(), data = Training_data_classification)
# 3.3 Baysian GLM
m_Logit_Bayesian <- arm::bayesglm(Buy_Sell ~ ., family=binomial(link="probit"), data = Training_data_classification)
# 4) Trying smaller model by utilizing the bestglm package -----
# https://rstudio-pubs-static.s3.amazonaws.com/2897_9220b21cfc0c43a396ff9abf122bb351.html
# http://www2.uaem.mx/r-mirror/web/packages/bestglm/vignettes/bestglm.pdf
Xy <- cbind(Training_data_classification[,which(names(Training_data_classification) != "Buy_Sell")],
Bell_Sell = Training_data_classification[,"Buy_Sell"])
# Produced error: Error in rep(-Inf, 2^p) : invalid 'times' argument
best_glm_binomial_probit <- bestglm::bestglm(Xy, family=binomial(link="probit"), method = "forward")
# http://stackoverflow.com/questions/12012746/bestglm-alternatives-for-dataset-with-many-variables
rm(Xy)
# 5) Smaller subset of predictor using the glmnet package ------
# ref:
# http://stats.stackexchange.com/questions/77546/how-to-interpret-glmnet
# https://web.stanford.edu/~hastie/Papers/Glmnet_Vignette.pdf
>>>>>>> 24a3fe80a629ed7915a6998dfa68630637e404de
#
# Predicted Buy/Sell given Buy/Sell
Prob_pred_Buy_given_Buy_Lasso   = paste(round(100 * sum(pred_Buy_given_Buy_Lasso == TRUE)  /Count_Buy,digits = 2),"%"),
Prob_pred_Buy_given_Sell_Lasso  = paste(round(100 * sum(pred_Buy_given_Sell_Lasso == TRUE) /Count_Sell,digits = 2),"%"),
Prob_pred_Sell_given_Buy_Lasso  = paste(round(100 * sum(pred_Sell_given_Buy_Lasso == TRUE) /Count_Buy,digits = 2),"%"),
Prob_pred_Sell_given_Sell_Lasso = paste(round(100 * sum(pred_Sell_given_Sell_Lasso == TRUE)/Count_Sell,digits = 2),"%"),
# Buy/Sell given Predicted Buy/Sell
Prob_Buy_given_pred_Buy_Lasso   = paste(round(100 * sum(Buy_given_Pred_Buy_Lasso == TRUE)  /sum(pred_glmnet_lasso_Buy_Sell == "Buy" ),digits = 2),"%"),
Prob_Buy_given_pred_Sell_Lasso  = paste(round(100 * sum(Buy_given_Pred_Sell_Lasso == TRUE) /sum(pred_glmnet_lasso_Buy_Sell == "Sell"),digits = 2),"%"),
Prob_Sell_given_pred_Buy_Lasso  = paste(round(100 * sum(Sell_given_Pred_Buy_Lasso == TRUE) /sum(pred_glmnet_lasso_Buy_Sell == "Buy" ),digits = 2),"%"),
Prob_Sell_given_pred_Sell_Lasso = paste(round(100 * sum(Sell_given_Pred_Sell_Lasso == TRUE)/sum(pred_glmnet_lasso_Buy_Sell == "Sell"),digits = 2),"%"),
# Accuracy
Pred_Accuracy_GLMnet_Lasso      = paste(round(100 * sum(Correct_pred_GLMnet_Lasso == TRUE) /Count,digits = 2),"%")) %>% as.vector()
Results <- cbind(fund = f, Results)
# Saving model to disk for future use
outCon <- file(paste0(save.model.path,f,".txt"), "w")
model.char <- rawToChar(serialize(glmnet_lasso, NULL, ascii=T))
cat(model.char, file=outCon); close(outCon)
return(Results)
}
getwd()
save.model.path <- "./ModelResults/"
for(f in funds_ids$FACTSET_FUND_ID) {
message(paste0("Processing fund:", f ,". Memory used: ", pryr::mem_used()))
qry <- paste0("SELECT * FROM fund_us_holdings_hist_w_symbols_and_sic where FACTSET_FUND_ID = '",f , "'")
data.set <- dbGetQuery(con, qry)
data.set <- data.set %>%
dplyr::mutate(Q_Ends = as.Date(timeDate::timeLastDayInQuarter(REPORT_DATE, format = "%Y-%m-%d", zone = "", FinCenter = "")),
HOLDING = as.numeric(HOLDING)) %>%
dplyr::group_by(FACTSET_FUND_ID, TICKER_EXCHANGE, Q_Ends) %>%
dplyr::summarise(HOLDING_tot = sum(HOLDING, na.rm = TRUE),
Symbol = dplyr::first(Symbol),
CAP_GROUP = as.factor(dplyr::first(CAP_GROUP)),
SECTOR_CODE = as.factor(dplyr::first(SECTOR_CODE))
) %>% dplyr::ungroup() %>%
# Enriching the ownership data with the fundamental data of the company
dplyr::left_join(Fundamental_data, by = c("Symbol", "Q_Ends")) %>%
dplyr::group_by(Symbol) %>% dplyr::arrange(Q_Ends) %>%
dplyr::mutate(HOLDING_chng = HOLDING_tot - lag(HOLDING_tot),
Buy_Sell = as.factor(ifelse(HOLDING_chng < 0, "Sell", "Buy"))) %>%
dplyr::ungroup() %>% dplyr::arrange(Symbol, Q_Ends)
# Specifying the regression variables
data.set <- na.omit(data.set) %>%
# Eliminating context (uneccessary) variable
dplyr::select(-FACTSET_FUND_ID, -TICKER_EXCHANGE, -Q_Ends, -HOLDING_tot, -Symbol)
Y_Var <- "Buy_Sell"
X_Var <-  setdiff(names(data.set), Y_Var)
# Splitting the data_set into training and testing set based on proportion variable
n_samples <- floor(NROW(data.set) * FRACTION_TRAINING)
sample_ids <- sample.int(n = NROW(data.set), size = n_samples, replace = FALSE)
Training_data <- data.set[sample_ids , c(Y_Var, X_Var)]
Test_data     <- data.set[-sample_ids, c(Y_Var, X_Var)]
X <- model.matrix( ~ .-1, data = Training_data[, X_Var])
Y <- as.numeric(Training_data[[Y_Var]])
# Cross validation for hyper-parameter estimation
N_folds <- 10
fold_id <- sample(1:N_folds,size=length(Y),replace=TRUE)
glmnet_lasso <- glmnet::cv.glmnet(X,Y, intercept=FALSE, foldid=fold_id, alpha=1, family = "binomial", type.measure="class") ## lasso regression - Sparse coeff
# Determine the optimal probability thereshold value to determine the class (buy vs sell)
# https://hopstat.wordpress.com/2014/12/19/a-small-introduction-to-the-rocr-package/
# Logit model
pred_logit <- prediction(predictions = predict(glmnet_lasso,
newx = model.matrix( ~ .-1, data = Training_data[, X_Var]),
# as.matrix(Training_data[,which(names(Training_data_classification) != "Buy_Sell")]),
s = "lambda.min", type = "response"),
labels = Training_data[, Y_Var])
# Equal cost for FP and FN
cost.perf  <- performance(pred_logit, "cost", cost.fp = 1, cost.fn = 1)
opt_threshold <- pred_logit@cutoffs[[1]][which.min(cost.perf@y.values[[1]])]
# Determining Predictive accuracy -----
X_test <- model.matrix( ~ .-1, data = Test_data[, X_Var])
Test_data$Y_prob <- predict(glmnet_lasso, s='lambda.min', newx=X_test, type="response")  %>% as.vector()
Test_data$pred_glmnet_lasso_Buy_Sell <- ifelse(Y_prob > opt_threshold, "Sell", "Buy")
# Creating Results data.frame
Results <- Test_data %>% dplyr::mutate(
# Predicted Buy/Sell given Buy/Sell
pred_Buy_given_Buy_Lasso    = ifelse(pred_glmnet_lasso_Buy_Sell == "Buy"  & Buy_Sell == "Buy" , TRUE, FALSE),
pred_Buy_given_Sell_Lasso   = ifelse(pred_glmnet_lasso_Buy_Sell == "Buy"  & Buy_Sell == "Sell", TRUE, FALSE),
pred_Sell_given_Buy_Lasso   = ifelse(pred_glmnet_lasso_Buy_Sell == "Sell" & Buy_Sell == "Buy" , TRUE, FALSE),
pred_Sell_given_Sell_Lasso  = ifelse(pred_glmnet_lasso_Buy_Sell == "Sell" & Buy_Sell == "Sell", TRUE, FALSE),
## Buy/Sell given Predicted Buy/Sell
Buy_given_Pred_Buy_Lasso   = ifelse(Buy_Sell == "Buy"  & pred_glmnet_lasso_Buy_Sell == "Buy" , TRUE, FALSE),
Buy_given_Pred_Sell_Lasso  = ifelse(Buy_Sell == "Buy"  & pred_glmnet_lasso_Buy_Sell == "Sell", TRUE, FALSE),
Sell_given_Pred_Buy_Lasso  = ifelse(Buy_Sell == "Sell" & pred_glmnet_lasso_Buy_Sell == "Buy" , TRUE, FALSE),
Sell_given_Pred_Sell_Lasso = ifelse(Buy_Sell == "Sell" & pred_glmnet_lasso_Buy_Sell == "Sell", TRUE, FALSE),
# Accuracy
Correct_pred_GLMnet_Lasso   = ifelse(pred_glmnet_lasso_Buy_Sell == Buy_Sell, TRUE, FALSE)
) %>% dplyr::summarise(
# TestData statistics
Count = as.integer(n()),
Count_Buy  = as.integer(sum(Buy_Sell == "Buy")),
Count_Sell = as.integer(sum(Buy_Sell == "Sell")),
Percent_buy = paste(round(100 * Count_Buy/Count, digits = 2), "%"),
Percent_sell =  paste(round(100 * Count_Sell/Count,digits = 2), "%"),
# GLMnet Lasso
# ============
#
# Predicted Buy/Sell given Buy/Sell
Prob_pred_Buy_given_Buy_Lasso   = paste(round(100 * sum(pred_Buy_given_Buy_Lasso == TRUE)  /Count_Buy,digits = 2),"%"),
Prob_pred_Buy_given_Sell_Lasso  = paste(round(100 * sum(pred_Buy_given_Sell_Lasso == TRUE) /Count_Sell,digits = 2),"%"),
Prob_pred_Sell_given_Buy_Lasso  = paste(round(100 * sum(pred_Sell_given_Buy_Lasso == TRUE) /Count_Buy,digits = 2),"%"),
Prob_pred_Sell_given_Sell_Lasso = paste(round(100 * sum(pred_Sell_given_Sell_Lasso == TRUE)/Count_Sell,digits = 2),"%"),
# Buy/Sell given Predicted Buy/Sell
Prob_Buy_given_pred_Buy_Lasso   = paste(round(100 * sum(Buy_given_Pred_Buy_Lasso == TRUE)  /sum(pred_glmnet_lasso_Buy_Sell == "Buy" ),digits = 2),"%"),
Prob_Buy_given_pred_Sell_Lasso  = paste(round(100 * sum(Buy_given_Pred_Sell_Lasso == TRUE) /sum(pred_glmnet_lasso_Buy_Sell == "Sell"),digits = 2),"%"),
Prob_Sell_given_pred_Buy_Lasso  = paste(round(100 * sum(Sell_given_Pred_Buy_Lasso == TRUE) /sum(pred_glmnet_lasso_Buy_Sell == "Buy" ),digits = 2),"%"),
Prob_Sell_given_pred_Sell_Lasso = paste(round(100 * sum(Sell_given_Pred_Sell_Lasso == TRUE)/sum(pred_glmnet_lasso_Buy_Sell == "Sell"),digits = 2),"%"),
# Accuracy
Pred_Accuracy_GLMnet_Lasso      = paste(round(100 * sum(Correct_pred_GLMnet_Lasso == TRUE) /Count,digits = 2),"%")) %>% as.vector()
Results <- cbind(fund = f, Results)
# Saving model to disk for future use
outCon <- file(paste0(save.model.path,f,".txt"), "w")
model.char <- rawToChar(serialize(glmnet_lasso, NULL, ascii=T))
cat(model.char, file=outCon); close(outCon)
return(Results)
}
counter <- 0  # about 49 tables to process
FRACTION_TRAINING <- 0.75
save.model.path <- "./ModelResults/"
Results_final <- list()
for(f in funds_ids$FACTSET_FUND_ID) {
counter <<- counter + 1
message(paste0("Processing fund:", f ,". Memory used: ", pryr::mem_used()))
qry <- paste0("SELECT * FROM fund_us_holdings_hist_w_symbols_and_sic where FACTSET_FUND_ID = '",f , "'")
data.set <- dbGetQuery(con, qry)
data.set <- data.set %>%
dplyr::mutate(Q_Ends = as.Date(timeDate::timeLastDayInQuarter(REPORT_DATE, format = "%Y-%m-%d", zone = "", FinCenter = "")),
HOLDING = as.numeric(HOLDING)) %>%
dplyr::group_by(FACTSET_FUND_ID, TICKER_EXCHANGE, Q_Ends) %>%
dplyr::summarise(HOLDING_tot = sum(HOLDING, na.rm = TRUE),
Symbol = dplyr::first(Symbol),
CAP_GROUP = as.factor(dplyr::first(CAP_GROUP)),
SECTOR_CODE = as.factor(dplyr::first(SECTOR_CODE))
) %>% dplyr::ungroup() %>%
# Enriching the ownership data with the fundamental data of the company
dplyr::left_join(Fundamental_data, by = c("Symbol", "Q_Ends")) %>%
dplyr::group_by(Symbol) %>% dplyr::arrange(Q_Ends) %>%
dplyr::mutate(HOLDING_chng = HOLDING_tot - lag(HOLDING_tot),
Buy_Sell = as.factor(ifelse(HOLDING_chng < 0, "Sell", "Buy"))) %>%
dplyr::ungroup() %>% dplyr::arrange(Symbol, Q_Ends)
# Specifying the regression variables
data.set <- na.omit(data.set) %>%
# Eliminating context (uneccessary) variable
dplyr::select(-FACTSET_FUND_ID, -TICKER_EXCHANGE, -Q_Ends, -HOLDING_tot, -Symbol)
Y_Var <- "Buy_Sell"
X_Var <-  setdiff(names(data.set), Y_Var)
# Splitting the data_set into training and testing set based on proportion variable
n_samples <- floor(NROW(data.set) * FRACTION_TRAINING)
sample_ids <- sample.int(n = NROW(data.set), size = n_samples, replace = FALSE)
Training_data <- data.set[sample_ids , c(Y_Var, X_Var)]
Test_data     <- data.set[-sample_ids, c(Y_Var, X_Var)]
X <- model.matrix( ~ .-1, data = Training_data[, X_Var])
Y <- as.numeric(Training_data[[Y_Var]])
# Cross validation for hyper-parameter estimation
N_folds <- 10
fold_id <- sample(1:N_folds,size=length(Y),replace=TRUE)
glmnet_lasso <- glmnet::cv.glmnet(X,Y, intercept=FALSE, foldid=fold_id, alpha=1, family = "binomial", type.measure="class") ## lasso regression - Sparse coeff
# Determine the optimal probability thereshold value to determine the class (buy vs sell)
# https://hopstat.wordpress.com/2014/12/19/a-small-introduction-to-the-rocr-package/
# Logit model
pred_logit <- prediction(predictions = predict(glmnet_lasso,
newx = model.matrix( ~ .-1, data = Training_data[, X_Var]),
# as.matrix(Training_data[,which(names(Training_data_classification) != "Buy_Sell")]),
s = "lambda.min", type = "response"),
labels = Training_data[, Y_Var])
# Equal cost for FP and FN
cost.perf  <- performance(pred_logit, "cost", cost.fp = 1, cost.fn = 1)
opt_threshold <- pred_logit@cutoffs[[1]][which.min(cost.perf@y.values[[1]])]
# Determining Predictive accuracy -----
X_test <- model.matrix( ~ .-1, data = Test_data[, X_Var])
Test_data$Y_prob <- predict(glmnet_lasso, s='lambda.min', newx=X_test, type="response")  %>% as.vector()
Test_data$pred_glmnet_lasso_Buy_Sell <- ifelse(Y_prob > opt_threshold, "Sell", "Buy")
# Creating Results data.frame
Results <- Test_data %>% dplyr::mutate(
# Predicted Buy/Sell given Buy/Sell
pred_Buy_given_Buy_Lasso    = ifelse(pred_glmnet_lasso_Buy_Sell == "Buy"  & Buy_Sell == "Buy" , TRUE, FALSE),
pred_Buy_given_Sell_Lasso   = ifelse(pred_glmnet_lasso_Buy_Sell == "Buy"  & Buy_Sell == "Sell", TRUE, FALSE),
pred_Sell_given_Buy_Lasso   = ifelse(pred_glmnet_lasso_Buy_Sell == "Sell" & Buy_Sell == "Buy" , TRUE, FALSE),
pred_Sell_given_Sell_Lasso  = ifelse(pred_glmnet_lasso_Buy_Sell == "Sell" & Buy_Sell == "Sell", TRUE, FALSE),
## Buy/Sell given Predicted Buy/Sell
Buy_given_Pred_Buy_Lasso   = ifelse(Buy_Sell == "Buy"  & pred_glmnet_lasso_Buy_Sell == "Buy" , TRUE, FALSE),
Buy_given_Pred_Sell_Lasso  = ifelse(Buy_Sell == "Buy"  & pred_glmnet_lasso_Buy_Sell == "Sell", TRUE, FALSE),
Sell_given_Pred_Buy_Lasso  = ifelse(Buy_Sell == "Sell" & pred_glmnet_lasso_Buy_Sell == "Buy" , TRUE, FALSE),
Sell_given_Pred_Sell_Lasso = ifelse(Buy_Sell == "Sell" & pred_glmnet_lasso_Buy_Sell == "Sell", TRUE, FALSE),
# Accuracy
Correct_pred_GLMnet_Lasso   = ifelse(pred_glmnet_lasso_Buy_Sell == Buy_Sell, TRUE, FALSE)
) %>% dplyr::summarise(
# TestData statistics
Count = as.integer(n()),
Count_Buy  = as.integer(sum(Buy_Sell == "Buy")),
Count_Sell = as.integer(sum(Buy_Sell == "Sell")),
Percent_buy = paste(round(100 * Count_Buy/Count, digits = 2), "%"),
Percent_sell =  paste(round(100 * Count_Sell/Count,digits = 2), "%"),
# GLMnet Lasso
# ============
#
# Predicted Buy/Sell given Buy/Sell
Prob_pred_Buy_given_Buy_Lasso   = paste(round(100 * sum(pred_Buy_given_Buy_Lasso == TRUE)  /Count_Buy,digits = 2),"%"),
Prob_pred_Buy_given_Sell_Lasso  = paste(round(100 * sum(pred_Buy_given_Sell_Lasso == TRUE) /Count_Sell,digits = 2),"%"),
Prob_pred_Sell_given_Buy_Lasso  = paste(round(100 * sum(pred_Sell_given_Buy_Lasso == TRUE) /Count_Buy,digits = 2),"%"),
Prob_pred_Sell_given_Sell_Lasso = paste(round(100 * sum(pred_Sell_given_Sell_Lasso == TRUE)/Count_Sell,digits = 2),"%"),
# Buy/Sell given Predicted Buy/Sell
Prob_Buy_given_pred_Buy_Lasso   = paste(round(100 * sum(Buy_given_Pred_Buy_Lasso == TRUE)  /sum(pred_glmnet_lasso_Buy_Sell == "Buy" ),digits = 2),"%"),
Prob_Buy_given_pred_Sell_Lasso  = paste(round(100 * sum(Buy_given_Pred_Sell_Lasso == TRUE) /sum(pred_glmnet_lasso_Buy_Sell == "Sell"),digits = 2),"%"),
Prob_Sell_given_pred_Buy_Lasso  = paste(round(100 * sum(Sell_given_Pred_Buy_Lasso == TRUE) /sum(pred_glmnet_lasso_Buy_Sell == "Buy" ),digits = 2),"%"),
Prob_Sell_given_pred_Sell_Lasso = paste(round(100 * sum(Sell_given_Pred_Sell_Lasso == TRUE)/sum(pred_glmnet_lasso_Buy_Sell == "Sell"),digits = 2),"%"),
# Accuracy
Pred_Accuracy_GLMnet_Lasso      = paste(round(100 * sum(Correct_pred_GLMnet_Lasso == TRUE) /Count,digits = 2),"%")) %>% as.vector()
Results <- cbind(fund = f, Results)
# Saving model to disk for future use
outCon <- file(paste0(save.model.path,f,".txt"), "w")
model.char <- rawToChar(serialize(glmnet_lasso, NULL, ascii=T))
cat(model.char, file=outCon); close(outCon)
Results_final[[counter]] <- Results
}
for(f in funds_ids$FACTSET_FUND_ID[[2]]) {
counter <<- counter + 1
message(paste0("Processing fund:", f ,". Memory used: ", pryr::mem_used()))
qry <- paste0("SELECT * FROM fund_us_holdings_hist_w_symbols_and_sic where FACTSET_FUND_ID = '",f , "'")
data.set <- dbGetQuery(con, qry)
data.set <- data.set %>%
dplyr::mutate(Q_Ends = as.Date(timeDate::timeLastDayInQuarter(REPORT_DATE, format = "%Y-%m-%d", zone = "", FinCenter = "")),
HOLDING = as.numeric(HOLDING)) %>%
dplyr::group_by(FACTSET_FUND_ID, TICKER_EXCHANGE, Q_Ends) %>%
dplyr::summarise(HOLDING_tot = sum(HOLDING, na.rm = TRUE),
Symbol = dplyr::first(Symbol),
CAP_GROUP = as.factor(dplyr::first(CAP_GROUP)),
SECTOR_CODE = as.factor(dplyr::first(SECTOR_CODE))
) %>% dplyr::ungroup() %>%
# Enriching the ownership data with the fundamental data of the company
dplyr::left_join(Fundamental_data, by = c("Symbol", "Q_Ends")) %>%
dplyr::group_by(Symbol) %>% dplyr::arrange(Q_Ends) %>%
dplyr::mutate(HOLDING_chng = HOLDING_tot - lag(HOLDING_tot),
Buy_Sell = as.factor(ifelse(HOLDING_chng < 0, "Sell", "Buy"))) %>%
dplyr::ungroup() %>% dplyr::arrange(Symbol, Q_Ends)
# Specifying the regression variables
data.set <- na.omit(data.set) %>%
# Eliminating context (uneccessary) variable
dplyr::select(-FACTSET_FUND_ID, -TICKER_EXCHANGE, -Q_Ends, -HOLDING_tot, -Symbol)
Y_Var <- "Buy_Sell"
X_Var <-  setdiff(names(data.set), Y_Var)
# Splitting the data_set into training and testing set based on proportion variable
n_samples <- floor(NROW(data.set) * FRACTION_TRAINING)
sample_ids <- sample.int(n = NROW(data.set), size = n_samples, replace = FALSE)
Training_data <- data.set[sample_ids , c(Y_Var, X_Var)]
Test_data     <- data.set[-sample_ids, c(Y_Var, X_Var)]
X <- model.matrix( ~ .-1, data = Training_data[, X_Var])
Y <- as.numeric(Training_data[[Y_Var]])
# Cross validation for hyper-parameter estimation
N_folds <- 10
fold_id <- sample(1:N_folds,size=length(Y),replace=TRUE)
glmnet_lasso <- glmnet::cv.glmnet(X,Y, intercept=FALSE, foldid=fold_id, alpha=1, family = "binomial", type.measure="class") ## lasso regression - Sparse coeff
# Determine the optimal probability thereshold value to determine the class (buy vs sell)
# https://hopstat.wordpress.com/2014/12/19/a-small-introduction-to-the-rocr-package/
# Logit model
pred_logit <- prediction(predictions = predict(glmnet_lasso,
newx = model.matrix( ~ .-1, data = Training_data[, X_Var]),
# as.matrix(Training_data[,which(names(Training_data_classification) != "Buy_Sell")]),
s = "lambda.min", type = "response"),
labels = Training_data[, Y_Var])
# Equal cost for FP and FN
cost.perf  <- performance(pred_logit, "cost", cost.fp = 1, cost.fn = 1)
opt_threshold <- pred_logit@cutoffs[[1]][which.min(cost.perf@y.values[[1]])]
# Determining Predictive accuracy -----
browser()
X_test <- model.matrix( ~ .-1, data = Test_data[, X_Var])
Test_data$Y_prob <- predict(glmnet_lasso, s='lambda.min', newx=X_test, type="response")  %>% as.vector()
Test_data$pred_glmnet_lasso_Buy_Sell <- ifelse(Y_prob > opt_threshold, "Sell", "Buy")
# Creating Results data.frame
Results <- Test_data %>% dplyr::mutate(
# Predicted Buy/Sell given Buy/Sell
pred_Buy_given_Buy_Lasso    = ifelse(pred_glmnet_lasso_Buy_Sell == "Buy"  & Buy_Sell == "Buy" , TRUE, FALSE),
pred_Buy_given_Sell_Lasso   = ifelse(pred_glmnet_lasso_Buy_Sell == "Buy"  & Buy_Sell == "Sell", TRUE, FALSE),
pred_Sell_given_Buy_Lasso   = ifelse(pred_glmnet_lasso_Buy_Sell == "Sell" & Buy_Sell == "Buy" , TRUE, FALSE),
pred_Sell_given_Sell_Lasso  = ifelse(pred_glmnet_lasso_Buy_Sell == "Sell" & Buy_Sell == "Sell", TRUE, FALSE),
## Buy/Sell given Predicted Buy/Sell
Buy_given_Pred_Buy_Lasso   = ifelse(Buy_Sell == "Buy"  & pred_glmnet_lasso_Buy_Sell == "Buy" , TRUE, FALSE),
Buy_given_Pred_Sell_Lasso  = ifelse(Buy_Sell == "Buy"  & pred_glmnet_lasso_Buy_Sell == "Sell", TRUE, FALSE),
Sell_given_Pred_Buy_Lasso  = ifelse(Buy_Sell == "Sell" & pred_glmnet_lasso_Buy_Sell == "Buy" , TRUE, FALSE),
Sell_given_Pred_Sell_Lasso = ifelse(Buy_Sell == "Sell" & pred_glmnet_lasso_Buy_Sell == "Sell", TRUE, FALSE),
# Accuracy
Correct_pred_GLMnet_Lasso   = ifelse(pred_glmnet_lasso_Buy_Sell == Buy_Sell, TRUE, FALSE)
) %>% dplyr::summarise(
# TestData statistics
Count = as.integer(n()),
Count_Buy  = as.integer(sum(Buy_Sell == "Buy")),
Count_Sell = as.integer(sum(Buy_Sell == "Sell")),
Percent_buy = paste(round(100 * Count_Buy/Count, digits = 2), "%"),
Percent_sell =  paste(round(100 * Count_Sell/Count,digits = 2), "%"),
# GLMnet Lasso
# ============
#
# Predicted Buy/Sell given Buy/Sell
Prob_pred_Buy_given_Buy_Lasso   = paste(round(100 * sum(pred_Buy_given_Buy_Lasso == TRUE)  /Count_Buy,digits = 2),"%"),
Prob_pred_Buy_given_Sell_Lasso  = paste(round(100 * sum(pred_Buy_given_Sell_Lasso == TRUE) /Count_Sell,digits = 2),"%"),
Prob_pred_Sell_given_Buy_Lasso  = paste(round(100 * sum(pred_Sell_given_Buy_Lasso == TRUE) /Count_Buy,digits = 2),"%"),
Prob_pred_Sell_given_Sell_Lasso = paste(round(100 * sum(pred_Sell_given_Sell_Lasso == TRUE)/Count_Sell,digits = 2),"%"),
# Buy/Sell given Predicted Buy/Sell
Prob_Buy_given_pred_Buy_Lasso   = paste(round(100 * sum(Buy_given_Pred_Buy_Lasso == TRUE)  /sum(pred_glmnet_lasso_Buy_Sell == "Buy" ),digits = 2),"%"),
Prob_Buy_given_pred_Sell_Lasso  = paste(round(100 * sum(Buy_given_Pred_Sell_Lasso == TRUE) /sum(pred_glmnet_lasso_Buy_Sell == "Sell"),digits = 2),"%"),
Prob_Sell_given_pred_Buy_Lasso  = paste(round(100 * sum(Sell_given_Pred_Buy_Lasso == TRUE) /sum(pred_glmnet_lasso_Buy_Sell == "Buy" ),digits = 2),"%"),
Prob_Sell_given_pred_Sell_Lasso = paste(round(100 * sum(Sell_given_Pred_Sell_Lasso == TRUE)/sum(pred_glmnet_lasso_Buy_Sell == "Sell"),digits = 2),"%"),
# Accuracy
Pred_Accuracy_GLMnet_Lasso      = paste(round(100 * sum(Correct_pred_GLMnet_Lasso == TRUE) /Count,digits = 2),"%")) %>% as.vector()
Results <- cbind(fund = f, Results)
# Saving model to disk for future use
outCon <- file(paste0(save.model.path,f,".txt"), "w")
model.char <- rawToChar(serialize(glmnet_lasso, NULL, ascii=T))
cat(model.char, file=outCon); close(outCon)
Results_final[[counter]] <- Results
}
dim(Test_data)
Test_data$Y_prob <- predict(glmnet_lasso, s='lambda.min', newx=X_test, type="response")  %>% as.vector()
Test_data$pred_glmnet_lasso_Buy_Sell <- ifelse(Y_prob > opt_threshold, "Sell", "Buy")
for(f in funds_ids$FACTSET_FUND_ID[[2]]) {
counter <<- counter + 1
message(paste0("Processing fund:", f ,". Memory used: ", pryr::mem_used()))
qry <- paste0("SELECT * FROM fund_us_holdings_hist_w_symbols_and_sic where FACTSET_FUND_ID = '",f , "'")
data.set <- dbGetQuery(con, qry)
data.set <- data.set %>%
dplyr::mutate(Q_Ends = as.Date(timeDate::timeLastDayInQuarter(REPORT_DATE, format = "%Y-%m-%d", zone = "", FinCenter = "")),
HOLDING = as.numeric(HOLDING)) %>%
dplyr::group_by(FACTSET_FUND_ID, TICKER_EXCHANGE, Q_Ends) %>%
dplyr::summarise(HOLDING_tot = sum(HOLDING, na.rm = TRUE),
Symbol = dplyr::first(Symbol),
CAP_GROUP = as.factor(dplyr::first(CAP_GROUP)),
SECTOR_CODE = as.factor(dplyr::first(SECTOR_CODE))
) %>% dplyr::ungroup() %>%
# Enriching the ownership data with the fundamental data of the company
dplyr::left_join(Fundamental_data, by = c("Symbol", "Q_Ends")) %>%
dplyr::group_by(Symbol) %>% dplyr::arrange(Q_Ends) %>%
dplyr::mutate(HOLDING_chng = HOLDING_tot - lag(HOLDING_tot),
Buy_Sell = as.factor(ifelse(HOLDING_chng < 0, "Sell", "Buy"))) %>%
dplyr::ungroup() %>% dplyr::arrange(Symbol, Q_Ends)
# Specifying the regression variables
data.set <- na.omit(data.set) %>%
# Eliminating context (uneccessary) variable
dplyr::select(-FACTSET_FUND_ID, -TICKER_EXCHANGE, -Q_Ends, -HOLDING_tot, -Symbol)
Y_Var <- "Buy_Sell"
X_Var <-  setdiff(names(data.set), Y_Var)
# Splitting the data_set into training and testing set based on proportion variable
n_samples <- floor(NROW(data.set) * FRACTION_TRAINING)
sample_ids <- sample.int(n = NROW(data.set), size = n_samples, replace = FALSE)
Training_data <- data.set[sample_ids , c(Y_Var, X_Var)]
Test_data     <- data.set[-sample_ids, c(Y_Var, X_Var)]
X <- model.matrix( ~ .-1, data = Training_data[, X_Var])
Y <- as.numeric(Training_data[[Y_Var]])
# Cross validation for hyper-parameter estimation
N_folds <- 10
fold_id <- sample(1:N_folds,size=length(Y),replace=TRUE)
glmnet_lasso <- glmnet::cv.glmnet(X,Y, intercept=FALSE, foldid=fold_id, alpha=1, family = "binomial", type.measure="class") ## lasso regression - Sparse coeff
# Determine the optimal probability thereshold value to determine the class (buy vs sell)
# https://hopstat.wordpress.com/2014/12/19/a-small-introduction-to-the-rocr-package/
# Logit model
pred_logit <- prediction(predictions = predict(glmnet_lasso,
newx = model.matrix( ~ .-1, data = Training_data[, X_Var]),
# as.matrix(Training_data[,which(names(Training_data_classification) != "Buy_Sell")]),
s = "lambda.min", type = "response"),
labels = Training_data[, Y_Var])
# Equal cost for FP and FN
cost.perf  <- performance(pred_logit, "cost", cost.fp = 1, cost.fn = 1)
opt_threshold <- pred_logit@cutoffs[[1]][which.min(cost.perf@y.values[[1]])]
# Determining Predictive accuracy -----
browser()
X_test <- model.matrix( ~ .-1, data = Test_data[, X_Var])
Test_data$Y_prob <- predict(glmnet_lasso, s='lambda.min', newx=X_test, type="response")  %>% as.vector()
Test_data$pred_glmnet_lasso_Buy_Sell <- ifelse(Test_data$Y_prob > opt_threshold, "Sell", "Buy")
# Creating Results data.frame
Results <- Test_data %>% dplyr::mutate(
# Predicted Buy/Sell given Buy/Sell
pred_Buy_given_Buy_Lasso    = ifelse(pred_glmnet_lasso_Buy_Sell == "Buy"  & Buy_Sell == "Buy" , TRUE, FALSE),
pred_Buy_given_Sell_Lasso   = ifelse(pred_glmnet_lasso_Buy_Sell == "Buy"  & Buy_Sell == "Sell", TRUE, FALSE),
pred_Sell_given_Buy_Lasso   = ifelse(pred_glmnet_lasso_Buy_Sell == "Sell" & Buy_Sell == "Buy" , TRUE, FALSE),
pred_Sell_given_Sell_Lasso  = ifelse(pred_glmnet_lasso_Buy_Sell == "Sell" & Buy_Sell == "Sell", TRUE, FALSE),
## Buy/Sell given Predicted Buy/Sell
Buy_given_Pred_Buy_Lasso   = ifelse(Buy_Sell == "Buy"  & pred_glmnet_lasso_Buy_Sell == "Buy" , TRUE, FALSE),
Buy_given_Pred_Sell_Lasso  = ifelse(Buy_Sell == "Buy"  & pred_glmnet_lasso_Buy_Sell == "Sell", TRUE, FALSE),
Sell_given_Pred_Buy_Lasso  = ifelse(Buy_Sell == "Sell" & pred_glmnet_lasso_Buy_Sell == "Buy" , TRUE, FALSE),
Sell_given_Pred_Sell_Lasso = ifelse(Buy_Sell == "Sell" & pred_glmnet_lasso_Buy_Sell == "Sell", TRUE, FALSE),
# Accuracy
Correct_pred_GLMnet_Lasso   = ifelse(pred_glmnet_lasso_Buy_Sell == Buy_Sell, TRUE, FALSE)
) %>% dplyr::summarise(
# TestData statistics
Count = as.integer(n()),
Count_Buy  = as.integer(sum(Buy_Sell == "Buy")),
Count_Sell = as.integer(sum(Buy_Sell == "Sell")),
Percent_buy = paste(round(100 * Count_Buy/Count, digits = 2), "%"),
Percent_sell =  paste(round(100 * Count_Sell/Count,digits = 2), "%"),
# GLMnet Lasso
<<<<<<< HEAD
# ============
#
# Predicted Buy/Sell given Buy/Sell
Prob_pred_Buy_given_Buy_Lasso   = paste(round(100 * sum(pred_Buy_given_Buy_Lasso == TRUE)  /Count_Buy,digits = 2),"%"),
Prob_pred_Buy_given_Sell_Lasso  = paste(round(100 * sum(pred_Buy_given_Sell_Lasso == TRUE) /Count_Sell,digits = 2),"%"),
Prob_pred_Sell_given_Buy_Lasso  = paste(round(100 * sum(pred_Sell_given_Buy_Lasso == TRUE) /Count_Buy,digits = 2),"%"),
Prob_pred_Sell_given_Sell_Lasso = paste(round(100 * sum(pred_Sell_given_Sell_Lasso == TRUE)/Count_Sell,digits = 2),"%"),
# Buy/Sell given Predicted Buy/Sell
Prob_Buy_given_pred_Buy_Lasso   = paste(round(100 * sum(Buy_given_Pred_Buy_Lasso == TRUE)  /sum(pred_glmnet_lasso_Buy_Sell == "Buy" ),digits = 2),"%"),
Prob_Buy_given_pred_Sell_Lasso  = paste(round(100 * sum(Buy_given_Pred_Sell_Lasso == TRUE) /sum(pred_glmnet_lasso_Buy_Sell == "Sell"),digits = 2),"%"),
Prob_Sell_given_pred_Buy_Lasso  = paste(round(100 * sum(Sell_given_Pred_Buy_Lasso == TRUE) /sum(pred_glmnet_lasso_Buy_Sell == "Buy" ),digits = 2),"%"),
Prob_Sell_given_pred_Sell_Lasso = paste(round(100 * sum(Sell_given_Pred_Sell_Lasso == TRUE)/sum(pred_glmnet_lasso_Buy_Sell == "Sell"),digits = 2),"%"),
# Accuracy
Pred_Accuracy_GLMnet_Lasso      = paste(round(100 * sum(Correct_pred_GLMnet_Lasso == TRUE) /Count,digits = 2),"%")) %>% as.vector()
Results <- cbind(fund = f, Results)
# Saving model to disk for future use
outCon <- file(paste0(save.model.path,f,".txt"), "w")
model.char <- rawToChar(serialize(glmnet_lasso, NULL, ascii=T))
cat(model.char, file=outCon); close(outCon)
Results_final[[counter]] <- Results
=======
Prob_Buy_given_Buy_Lasso   = paste(round(100 * sum(pred_Buy_given_Buy_Lasso == TRUE)  /Count_Buy,digits = 2),"%"),
Prob_Buy_given_Sell_Lasso  = paste(round(100 * sum(pred_Buy_given_Sell_Lasso == TRUE) /Count_Sell,digits = 2),"%"),
Prob_Sell_given_Buy_Lasso  = paste(round(100 * sum(pred_Sell_given_Buy_Lasso == TRUE) /Count_Buy,digits = 2),"%"),
Prob_Sell_given_Sell_Lasso = paste(round(100 * sum(pred_Sell_given_Sell_Lasso == TRUE)/Count_Sell,digits = 2),"%"),
accuracy_GLMnet_Lasso      = paste(round(100 * sum(Correct_pred_GLMnet_Lasso == TRUE) /Count,digits = 2),"%"),
#GLMnet Ridge
Prob_Buy_given_Buy_Ridge   = paste(round(100 * sum(pred_Buy_given_Buy_Ridge == TRUE)  /Count_Buy,digits = 2),"%"),
Prob_Buy_given_Sell_Ridge  = paste(round(100 * sum(pred_Buy_given_Sell_Ridge == TRUE) /Count_Sell,digits = 2),"%"),
Prob_Sell_given_Buy_Ridge  = paste(round(100 * sum(pred_Sell_given_Buy_Ridge == TRUE) /Count_Buy,digits = 2),"%"),
Prob_Sell_given_Sell_Ridge = paste(round(100 * sum(pred_Sell_given_Sell_Ridge == TRUE)/Count_Sell,digits = 2),"%"),
accuracy_GLMnet_Ridge      = paste(round(100 * sum(Correct_pred_GLMnet_Ridge == TRUE)/Count, digits = 2), "%")) %>%
t()
probability_threshold   = paste0("Threshold: ",round(100 * threshold, digits = 2), "%")
colnames(Results_Summary) <- probability_threshold
res <- list(Summary = Results_Summary, TestResults = Results_focus, Thresh = threshold)
return(res)
}
Results_Summary_1 <- ModelPreictionResults(threshold = opt_t )$Summary # Result summary associated with opt_t
Results_Summary_2 <- ModelPreictionResults(threshold = opt_t2)$Summary # Result summary associated with opt_t2
Results_Summary_3 <- ModelPreictionResults(threshold = opt_t3)$Summary # Result summary associated with opt_t3
Results_Summary_4 <- ModelPreictionResults(threshold = opt_t4)$Summary # Result summary associated with opt_t4
Results_Summary_5 <- ModelPreictionResults(threshold = opt_t5)$Summary # Result summary associated with opt_t5
Results_Summary_all <- cbind(Results_Summary_1, Results_Summary_2, Results_Summary_3, Results_Summary_4, Results_Summary_5)
View(Results_Summary_all)
(opt_t, opt_t2, opt_t3, opt_t4, opt_t5)
(opt_t, opt_t2, opt_t3, opt_t4, opt_t5)
c(opt_t, opt_t2, opt_t3, opt_t4, opt_t5)
rank(c(opt_t, opt_t2, opt_t3, opt_t4, opt_t5))
Results_Summary_all <- Results_Summary_all[, rank(c(opt_t, opt_t2, opt_t3, opt_t4, opt_t5))]
View(Results_Summary_all)
Results_Summary_all <- cbind(Results_Summary_5, Results_Summary_4, Results_Summary_2, Results_Summary_1, Results_Summary_3)
View(Results_Summary_all)
opt_t_models
write.csv(Results_Summary_all, "./output_files/Results_Summary.csv", row.names = TRUE, col.names = TRUE)
=======
SharkPositions_good <- data.set <- dplyr::semi_join(SharkPositions, good_symbols_list, by = "Symbol")
data_path <- "~/Data/Fundamentals_9_17_2016/fundamentals_9_17_2016"
files <- dir(path = data_path, pattern = "_Request")
data.set <- dbReadTable(con, "SharkPositions_good") %>% dplyr::mutate(Date = as.Date(Date))
tbls_list <- dbListTables(con)
counter <- 0
pryr::mem_used()
for(t in tbls_list[1:10]) {
# Verbose msg
counter <<- counter + 1
message(paste0("Processing table number: ", counter, ". TableName/Fundamental data: ", t, ". Memory used: ", pryr::mem_used()))
# Looping through all the tables in the db excluding the sharkpositions table
if (t %in% c("sharkpositions", "sharkpositions_good")) next
data.X <- dbReadTable(con, t) %>% dplyr::mutate(Date = as.Date(Date)) %>%
dplyr::rowwise() %>% dplyr::mutate(Next_Pos_date = suppressWarnings(Positions_dates[min(which(Positions_dates > Date))]))
# Renaming the variable before adding them to the data_set
names(data.X)[which(names(data.X) == "Date")] <- paste0("Date_", t)
if(NCOL(data.X) > 3) names(data.X)[which(names(data.X) == "Value")] <- t
# Constructing the dataset
data.set <<- dplyr::left_join(data.set, data.X, by = c("Symbol", "Date" = "Next_Pos_date"))
saveRDS(data.set, file = "DataSet.rds")
rm(data.X)
gc()
}
Positions_dates <- sort(unique(SharkPositions$Date))
data.set <- dbReadTable(con, "SharkPositions_good") %>% dplyr::mutate(Date = as.Date(Date))
tbls_list <- dbListTables(con)
counter <- 0
pryr::mem_used()
for(t in tbls_list[1:10]) {
# Verbose msg
counter <<- counter + 1
message(paste0("Processing table number: ", counter, ". TableName/Fundamental data: ", t, ". Memory used: ", pryr::mem_used()))
# Looping through all the tables in the db excluding the sharkpositions table
if (t %in% c("sharkpositions", "sharkpositions_good")) next
data.X <- dbReadTable(con, t) %>% dplyr::mutate(Date = as.Date(Date)) %>%
dplyr::rowwise() %>% dplyr::mutate(Next_Pos_date = suppressWarnings(Positions_dates[min(which(Positions_dates > Date))]))
# Renaming the variable before adding them to the data_set
names(data.X)[which(names(data.X) == "Date")] <- paste0("Date_", t)
if(NCOL(data.X) > 3) names(data.X)[which(names(data.X) == "Value")] <- t
# Constructing the dataset
data.set <<- dplyr::left_join(data.set, data.X, by = c("Symbol", "Date" = "Next_Pos_date"))
saveRDS(data.set, file = "DataSet.rds")
rm(data.X)
gc()
}
gc()
pryr::mem_used()
save.image("WorkSpace_1tmp.RData")
pryr::mem_used()
for(i in 1:10){
gc()
sleep(0.5)
}
for(i in 1:10){
gc()
Sys.sleep(0.5)
}
pryr::mem_used()
gc()
pryr::mem_used()
Positions_dates <- sort(unique(SharkPositions$Date))
good_symbols_list <- dplyr::filter(transaction_per_symbol_per_year, Count <= 4) %>% dplyr::distinct()
library(RMySQL)
con <- dbConnect(RMySQL::MySQL(), default.file = .rmysql.settingsfile, group = "local_intel")
SharkPositions_good <- data.set <- dplyr::semi_join(SharkPositions, good_symbols_list, by = "Symbol")
data_path <- "~/Data/Fundamentals_9_17_2016/fundamentals_9_17_2016"
saveRDS(data.set, file = "DataSet.rds")
tbls_list <- dbListTables(con)
counter <- 0
pryr::mem_used()
for(t in tbls_list[1:8]) {
# Verbose msg
counter <<- counter + 1
data.set <<- readRDS(DataSet.rds)
message(paste0("Processing table number: ", counter, ". TableName/Fundamental data: ", t, ". Memory used: ", pryr::mem_used()))
# Looping through all the tables in the db excluding the sharkpositions table
if (t %in% c("sharkpositions", "sharkpositions_good")) next
data.X <- dbReadTable(con, t) %>% dplyr::mutate(Date = as.Date(Date)) %>%
dplyr::rowwise() %>% dplyr::mutate(Next_Pos_date = suppressWarnings(Positions_dates[min(which(Positions_dates > Date))]))
# Renaming the variable before adding them to the data_set
names(data.X)[which(names(data.X) == "Date")] <- paste0("Date_", t)
if(NCOL(data.X) > 3) names(data.X)[which(names(data.X) == "Value")] <- t
# Constructing the dataset
data.set <<- dplyr::left_join(data.set, data.X, by = c("Symbol", "Date" = "Next_Pos_date"))
saveRDS(data.set, file = "DataSet.rds")
rm(data.X)
rm(data.set)
gc()
}
tbls_list <- dbListTables(con)
counter <- 0
pryr::mem_used()
for(t in tbls_list[1:8]) {
# Verbose msg
counter <<- counter + 1
data.set <<- readRDS("DataSet.rds")
message(paste0("Processing table number: ", counter, ". TableName/Fundamental data: ", t, ". Memory used: ", pryr::mem_used()))
# Looping through all the tables in the db excluding the sharkpositions table
if (t %in% c("sharkpositions", "sharkpositions_good")) next
data.X <- dbReadTable(con, t) %>% dplyr::mutate(Date = as.Date(Date)) %>%
dplyr::rowwise() %>% dplyr::mutate(Next_Pos_date = suppressWarnings(Positions_dates[min(which(Positions_dates > Date))]))
# Renaming the variable before adding them to the data_set
names(data.X)[which(names(data.X) == "Date")] <- paste0("Date_", t)
if(NCOL(data.X) > 3) names(data.X)[which(names(data.X) == "Value")] <- t
# Constructing the dataset
data.set <<- dplyr::left_join(data.set, data.X, by = c("Symbol", "Date" = "Next_Pos_date"))
saveRDS(data.set, file = "DataSet.rds")
rm(data.X)
rm(data.set)
gc()
}
pryr::mem_used()
counter
for(t in tbls_list[9:17]) {
# Verbose msg
counter <<- counter + 1
data.set <<- readRDS("DataSet.rds")
message(paste0("Processing table number: ", counter, ". TableName/Fundamental data: ", t, ". Memory used: ", pryr::mem_used()))
>>>>>>> 0c484179b03a9984cb4a73d42a5e6d8bb53378ce
# Looping through all the tables in the db excluding the sharkpositions table
if (t %in% c("sharkpositions", "sharkpositions_good")) next
data.X <- dbReadTable(con, t) %>% dplyr::mutate(Date = as.Date(Date)) %>%
dplyr::rowwise() %>% dplyr::mutate(Next_Pos_date = suppressWarnings(Positions_dates[min(which(Positions_dates > Date))]))
# Renaming the variable before adding them to the data_set
names(data.X)[which(names(data.X) == "Date")] <- paste0("Date_", t)
if(NCOL(data.X) > 3) names(data.X)[which(names(data.X) == "Value")] <- t
# Constructing the dataset
data.set <<- dplyr::left_join(data.set, data.X, by = c("Symbol", "Date" = "Next_Pos_date"))
saveRDS(data.set, file = "DataSet.rds")
rm(data.X)
rm(data.set)
gc()
}
library(RMySQL)
con <- dbConnect(RMySQL::MySQL(), default.file = .rmysql.settingsfile, group = "local_intel")
dbListTables(con)
dbWriteTable(con, "SharkPositions", SharkPositions)
Positions_dates <- sort(unique(SharkPositions$Date))
good_symbols_list <- dplyr::filter(transaction_per_symbol_per_year, Count <= 4) %>% dplyr::distinct()
SharkPositions_good <- data.set <- dplyr::semi_join(SharkPositions, good_symbols_list, by = "Symbol")
data_path <- "~/Data/Fundamentals_9_17_2016/fundamentals_9_17_2016"
files <- dir(path = data_path, pattern = "_Request")
pryr::mem_used()
counter <- 0
tbls_list <- dbListTables(con)
saveRDS(data.set, file = "DataSet.rds")
for(t in tbls_list[1:9]) {
# Verbose msg
counter <<- counter + 1
data.set <<- readRDS("DataSet.rds")
message(paste0("Processing table number: ", counter, ". TableName/Fundamental data: ", t, ". Memory used: ", pryr::mem_used()))
# Looping through all the tables in the db excluding the sharkpositions table
if (t %in% c("sharkpositions", "sharkpositions_good")) next
data.X <- dbReadTable(con, t) %>% dplyr::mutate(Date = as.Date(Date)) %>%
dplyr::rowwise() %>% dplyr::mutate(Next_Pos_date = suppressWarnings(Positions_dates[min(which(Positions_dates > Date))]))
# Renaming the variable before adding them to the data_set
names(data.X)[which(names(data.X) == "Date")] <- paste0("Date_", t)
if(NCOL(data.X) > 3) names(data.X)[which(names(data.X) == "Value")] <- t
# Constructing the dataset
data.set <<- dplyr::left_join(data.set, data.X, by = c("Symbol", "Date" = "Next_Pos_date"))
saveRDS(data.set, file = "DataSet.rds")
rm(data.X)
rm(data.set)
gc()
}
Positions_dates <- sort(unique(SharkPositions$Date))
good_symbols_list <- dplyr::filter(transaction_per_symbol_per_year, Count <= 4) %>% dplyr::distinct()
library(RMySQL)
con <- dbConnect(RMySQL::MySQL(), default.file = .rmysql.settingsfile, group = "local_intel")
SharkPositions_good <- data.set <- dplyr::semi_join(SharkPositions, good_symbols_list, by = "Symbol")
tbls_list <- dbListTables(con)
for(t in tbls_list[10:19]) {
# Verbose msg
counter <<- counter + 1
data.set <<- readRDS("DataSet.rds")
message(paste0("Processing table number: ", counter, ". TableName/Fundamental data: ", t, ". Memory used: ", pryr::mem_used()))
# Looping through all the tables in the db excluding the sharkpositions table
if (t %in% c("sharkpositions", "sharkpositions_good")) next
data.X <- dbReadTable(con, t) %>% dplyr::mutate(Date = as.Date(Date)) %>%
dplyr::rowwise() %>% dplyr::mutate(Next_Pos_date = suppressWarnings(Positions_dates[min(which(Positions_dates > Date))]))
# Renaming the variable before adding them to the data_set
names(data.X)[which(names(data.X) == "Date")] <- paste0("Date_", t)
if(NCOL(data.X) > 3) names(data.X)[which(names(data.X) == "Value")] <- t
# Constructing the dataset
data.set <<- dplyr::left_join(data.set, data.X, by = c("Symbol", "Date" = "Next_Pos_date"))
saveRDS(data.set, file = "DataSet.rds")
rm(data.X)
rm(data.set)
gc()
}
counter <- 9
pryr::mem_used()
for(t in tbls_list[10:19]) {
# Verbose msg
counter <<- counter + 1
data.set <<- readRDS("DataSet.rds")
message(paste0("Processing table number: ", counter, ". TableName/Fundamental data: ", t, ". Memory used: ", pryr::mem_used()))
# Looping through all the tables in the db excluding the sharkpositions table
if (t %in% c("sharkpositions", "sharkpositions_good")) next
data.X <- dbReadTable(con, t) %>% dplyr::mutate(Date = as.Date(Date)) %>%
dplyr::rowwise() %>% dplyr::mutate(Next_Pos_date = suppressWarnings(Positions_dates[min(which(Positions_dates > Date))]))
# Renaming the variable before adding them to the data_set
names(data.X)[which(names(data.X) == "Date")] <- paste0("Date_", t)
if(NCOL(data.X) > 3) names(data.X)[which(names(data.X) == "Value")] <- t
# Constructing the dataset
data.set <<- dplyr::left_join(data.set, data.X, by = c("Symbol", "Date" = "Next_Pos_date"))
saveRDS(data.set, file = "DataSet.rds")
rm(data.X)
rm(data.set)
gc()
}
pryr::mem_used()
data.set <<- readRDS("DataSet.rds")
pryr::mem_used()
View(data.set)
NROW(SharkPositions)
NROW(data.set)
library(RMySQL)
con <- dbConnect(RMySQL::MySQL(),  default.file = "~/.my.cnf", group = "local_intel")
dbListTables(con)
dbListTables(con)
data.set <- dbReadTable(con, "SharkPositions_good") %>% dplyr::mutate(Date = as.Date(Date))
# saveRDS(data.set, file = "DataSet.rds")
tbls_list <- dbListTables(con)
counter <- 0
pryr::mem_used()
for(t in tbls_list) {
# Verbose msg
counter <<- counter + 1
#data.set <<- readRDS("DataSet.rds")
message(paste0("Processing table number: ", counter, ". TableName/Fundamental data: ", t, ". Memory used: ", pryr::mem_used()))
# Looping through all the tables in the db excluding the sharkpositions table
if (t %in% c("sharkpositions", "sharkpositions_good", "SharkPositions" , "SharkPositions_good" , "data_set")) next
data.X <- dbReadTable(con, t) %>% dplyr::mutate(Date = as.Date(Date)) %>%
dplyr::rowwise() %>%
dplyr::mutate(Next_Pos_date = suppressWarnings(Positions_dates[min(which(Positions_dates > Date))])) %>%
dplyr::ungroup() %>%
# Keeping only 1 data point per symbol per Position Date
dplyr::arrange(Symbol, desc(Date)) %>%
dplyr::distinct(Symbol, Next_Pos_date, .keep_all = TRUE)
# Renaming the variable before adding them to the data_set
names(data.X)[which(names(data.X) == "Date")] <- paste0("Date_", t)
if(NCOL(data.X) > 3) names(data.X)[which(names(data.X) == "Value")] <- t
# Constructing the dataset
data.set <<- dplyr::left_join(data.set, data.X, by = c("Symbol", "Date" = "Next_Pos_date"))
#saveRDS(data.set, file = "DataSet.rds")
names(data.set)
rm(data.X)
gc()
}
data.set <- data.set %>% dplyr::arrange(Symbol, Date)
Positions_dates <- sort(unique(SharkPositions$Date))
data.set <- dbReadTable(con, "SharkPositions_good") %>% dplyr::mutate(Date = as.Date(Date))
# saveRDS(data.set, file = "DataSet.rds")
tbls_list <- dbListTables(con)
counter <- 0
pryr::mem_used()
for(t in tbls_list) {
# Verbose msg
counter <<- counter + 1
#data.set <<- readRDS("DataSet.rds")
message(paste0("Processing table number: ", counter, ". TableName/Fundamental data: ", t, ". Memory used: ", pryr::mem_used()))
# Looping through all the tables in the db excluding the sharkpositions table
if (t %in% c("sharkpositions", "sharkpositions_good", "SharkPositions" , "SharkPositions_good" , "data_set")) next
data.X <- dbReadTable(con, t) %>% dplyr::mutate(Date = as.Date(Date)) %>%
dplyr::rowwise() %>%
dplyr::mutate(Next_Pos_date = suppressWarnings(Positions_dates[min(which(Positions_dates > Date))])) %>%
dplyr::ungroup() %>%
# Keeping only 1 data point per symbol per Position Date
dplyr::arrange(Symbol, desc(Date)) %>%
dplyr::distinct(Symbol, Next_Pos_date, .keep_all = TRUE)
# Renaming the variable before adding them to the data_set
names(data.X)[which(names(data.X) == "Date")] <- paste0("Date_", t)
if(NCOL(data.X) > 3) names(data.X)[which(names(data.X) == "Value")] <- t
# Constructing the dataset
data.set <<- dplyr::left_join(data.set, data.X, by = c("Symbol", "Date" = "Next_Pos_date"))
#saveRDS(data.set, file = "DataSet.rds")
names(data.set)
rm(data.X)
gc()
>>>>>>> 24a3fe80a629ed7915a6998dfa68630637e404de
}
counter <- 0  # about 49 tables to process
>>>>>>> e7caf8b09f42bcef33a8a796ced2a905076b8d82
FRACTION_TRAINING <- 0.75
save.model.path <- "./ModelResults/"
Results_final <- list()
for(f in funds_ids$FACTSET_FUND_ID) {
counter <<- counter + 1
message(paste0("Processing fund:", f ,". Memory used: ", pryr::mem_used()))
qry <- paste0("SELECT * FROM fund_us_holdings_hist_w_symbols_and_sic where FACTSET_FUND_ID = '",f , "'")
data.set <- dbGetQuery(con, qry)
data.set <- data.set %>%
dplyr::mutate(Q_Ends = as.Date(timeDate::timeLastDayInQuarter(REPORT_DATE, format = "%Y-%m-%d", zone = "", FinCenter = "")),
HOLDING = as.numeric(HOLDING)) %>%
dplyr::group_by(FACTSET_FUND_ID, TICKER_EXCHANGE, Q_Ends) %>%
dplyr::summarise(HOLDING_tot = sum(HOLDING, na.rm = TRUE),
Symbol = dplyr::first(Symbol),
CAP_GROUP = as.factor(dplyr::first(CAP_GROUP)),
SECTOR_CODE = as.factor(dplyr::first(SECTOR_CODE))
) %>% dplyr::ungroup() %>%
# Enriching the ownership data with the fundamental data of the company
dplyr::left_join(Fundamental_data, by = c("Symbol", "Q_Ends")) %>%
dplyr::group_by(Symbol) %>% dplyr::arrange(Q_Ends) %>%
dplyr::mutate(HOLDING_chng = HOLDING_tot - lag(HOLDING_tot),
Buy_Sell = as.factor(ifelse(HOLDING_chng < 0, "Sell", "Buy"))) %>%
dplyr::ungroup() %>% dplyr::arrange(Symbol, Q_Ends)
# Specifying the regression variables
data.set <- na.omit(data.set) %>%
# Eliminating context (uneccessary) variable
dplyr::select(-FACTSET_FUND_ID, -TICKER_EXCHANGE, -Q_Ends, -HOLDING_tot, -Symbol)
Y_Var <- "Buy_Sell"
X_Var <-  setdiff(names(data.set), Y_Var)
# Splitting the data_set into training and testing set based on proportion variable
n_samples <- floor(NROW(data.set) * FRACTION_TRAINING)
sample_ids <- sample.int(n = NROW(data.set), size = n_samples, replace = FALSE)
Training_data <- data.set[sample_ids , c(Y_Var, X_Var)]
Test_data     <- data.set[-sample_ids, c(Y_Var, X_Var)]
X <- model.matrix( ~ .-1, data = Training_data[, X_Var])
Y <- as.numeric(Training_data[[Y_Var]])
# Cross validation for hyper-parameter estimation
N_folds <- 10
fold_id <- sample(1:N_folds,size=length(Y),replace=TRUE)
glmnet_lasso <- glmnet::cv.glmnet(X,Y, intercept=FALSE, foldid=fold_id, alpha=1, family = "binomial", type.measure="class") ## lasso regression - Sparse coeff
# Determine the optimal probability thereshold value to determine the class (buy vs sell)
# https://hopstat.wordpress.com/2014/12/19/a-small-introduction-to-the-rocr-package/
# Logit model
pred_logit <- prediction(predictions = predict(glmnet_lasso,
newx = model.matrix( ~ .-1, data = Training_data[, X_Var]),
# as.matrix(Training_data[,which(names(Training_data_classification) != "Buy_Sell")]),
s = "lambda.min", type = "response"),
labels = Training_data[, Y_Var])
# Equal cost for FP and FN
cost.perf  <- performance(pred_logit, "cost", cost.fp = 1, cost.fn = 1)
opt_threshold <- pred_logit@cutoffs[[1]][which.min(cost.perf@y.values[[1]])]
# Determining Predictive accuracy -----
browser()
X_test <- model.matrix( ~ .-1, data = Test_data[, X_Var])
Test_data$Y_prob <- predict(glmnet_lasso, s='lambda.min', newx=X_test, type="response")  %>% as.vector()
Test_data$pred_glmnet_lasso_Buy_Sell <- ifelse(Test_data$Y_prob > opt_threshold, "Sell", "Buy")
# Creating Results data.frame
Results <- Test_data %>% dplyr::mutate(
# Predicted Buy/Sell given Buy/Sell
pred_Buy_given_Buy_Lasso    = ifelse(pred_glmnet_lasso_Buy_Sell == "Buy"  & Buy_Sell == "Buy" , TRUE, FALSE),
pred_Buy_given_Sell_Lasso   = ifelse(pred_glmnet_lasso_Buy_Sell == "Buy"  & Buy_Sell == "Sell", TRUE, FALSE),
pred_Sell_given_Buy_Lasso   = ifelse(pred_glmnet_lasso_Buy_Sell == "Sell" & Buy_Sell == "Buy" , TRUE, FALSE),
pred_Sell_given_Sell_Lasso  = ifelse(pred_glmnet_lasso_Buy_Sell == "Sell" & Buy_Sell == "Sell", TRUE, FALSE),
## Buy/Sell given Predicted Buy/Sell
Buy_given_Pred_Buy_Lasso   = ifelse(Buy_Sell == "Buy"  & pred_glmnet_lasso_Buy_Sell == "Buy" , TRUE, FALSE),
Buy_given_Pred_Sell_Lasso  = ifelse(Buy_Sell == "Buy"  & pred_glmnet_lasso_Buy_Sell == "Sell", TRUE, FALSE),
Sell_given_Pred_Buy_Lasso  = ifelse(Buy_Sell == "Sell" & pred_glmnet_lasso_Buy_Sell == "Buy" , TRUE, FALSE),
Sell_given_Pred_Sell_Lasso = ifelse(Buy_Sell == "Sell" & pred_glmnet_lasso_Buy_Sell == "Sell", TRUE, FALSE),
# Accuracy
Correct_pred_GLMnet_Lasso   = ifelse(pred_glmnet_lasso_Buy_Sell == Buy_Sell, TRUE, FALSE)
) %>% dplyr::summarise(
# TestData statistics
Count = as.integer(n()),
Count_Buy  = as.integer(sum(Buy_Sell == "Buy")),
Count_Sell = as.integer(sum(Buy_Sell == "Sell")),
Percent_buy = paste(round(100 * Count_Buy/Count, digits = 2), "%"),
Percent_sell =  paste(round(100 * Count_Sell/Count,digits = 2), "%"),
# GLMnet Lasso
# ============
#
# Predicted Buy/Sell given Buy/Sell
Prob_pred_Buy_given_Buy_Lasso   = paste(round(100 * sum(pred_Buy_given_Buy_Lasso == TRUE)  /Count_Buy,digits = 2),"%"),
Prob_pred_Buy_given_Sell_Lasso  = paste(round(100 * sum(pred_Buy_given_Sell_Lasso == TRUE) /Count_Sell,digits = 2),"%"),
Prob_pred_Sell_given_Buy_Lasso  = paste(round(100 * sum(pred_Sell_given_Buy_Lasso == TRUE) /Count_Buy,digits = 2),"%"),
Prob_pred_Sell_given_Sell_Lasso = paste(round(100 * sum(pred_Sell_given_Sell_Lasso == TRUE)/Count_Sell,digits = 2),"%"),
# Buy/Sell given Predicted Buy/Sell
Prob_Buy_given_pred_Buy_Lasso   = paste(round(100 * sum(Buy_given_Pred_Buy_Lasso == TRUE)  /sum(pred_glmnet_lasso_Buy_Sell == "Buy" ),digits = 2),"%"),
Prob_Buy_given_pred_Sell_Lasso  = paste(round(100 * sum(Buy_given_Pred_Sell_Lasso == TRUE) /sum(pred_glmnet_lasso_Buy_Sell == "Sell"),digits = 2),"%"),
Prob_Sell_given_pred_Buy_Lasso  = paste(round(100 * sum(Sell_given_Pred_Buy_Lasso == TRUE) /sum(pred_glmnet_lasso_Buy_Sell == "Buy" ),digits = 2),"%"),
Prob_Sell_given_pred_Sell_Lasso = paste(round(100 * sum(Sell_given_Pred_Sell_Lasso == TRUE)/sum(pred_glmnet_lasso_Buy_Sell == "Sell"),digits = 2),"%"),
# Accuracy
Pred_Accuracy_GLMnet_Lasso      = paste(round(100 * sum(Correct_pred_GLMnet_Lasso == TRUE) /Count,digits = 2),"%")) %>% as.vector()
Results <- cbind(fund = f, Results)
# Saving model to disk for future use
outCon <- file(paste0(save.model.path,f,".txt"), "w")
model.char <- rawToChar(serialize(glmnet_lasso, NULL, ascii=T))
cat(model.char, file=outCon); close(outCon)
Results_final[[counter]] <- Results
}
<<<<<<< HEAD
Results_final2 <- dplyr::bind_rows(Results_final)
View(Results_final2)
=======
scanned_data <- data.set3[, c(Y_var, X_var)] %>% # partition() %>%
dplyr::group_by(Year) %>% dplyr::do(res = my_func(.))
RANDOM_TRAINING <- FALSE
FRACTION_TRAINING <- 0.75
if(RANDOM_TRAINING == TRUE) {
n_samples <- floor(NROW(data.set3) * FRACTION_TRAINING)
sample_ids <- sample.int(n = NROW(data.set3), size = n_samples, replace = FALSE)
Training_data_regression <- data.set3[sample_ids , c(Y_var, X_var)]
Test_data_regression     <- data.set3[-sample_ids, c(Y_var, X_var)]
} else {
# Splitting training/Testing
Years_dataset <- as.numeric(sort(unique(data.set3$Year)))
Test_years <- c(2015)
Training_years <- setdiff(Years_dataset, Test_years)
Training_data_regression <- dplyr::filter(data.set3, Year %in% Training_years) %>%
dplyr::select_(.dots = c(Y_var, X_var))
Test_data_regression <- dplyr::filter(data.set3, Year %in% Test_years) %>%
dplyr::select_(.dots = c(Y_var, X_var))
}
# Classification data sets -----
Training_data_classification <- Training_data_regression
Training_data_classification$Buy_Sell <- as.factor(ifelse(Training_data_regression[,Y_var] > 0, "Buy", "Sell"))
Training_data_classification <- Training_data_classification[, -which(names(Training_data_classification) == Y_var)]
Test_data_classification <- Test_data_regression
Test_data_classification$Buy_Sell <- as.factor(ifelse(Test_data_regression[,Y_var] > 0, "Buy", "Sell"))
Test_data_classification <- Test_data_classification[, -which(names(Test_data_classification) == Y_var)]
library(FSelector)
install.packages("FSelector")
features_information.gain_classification <- information.gain(formula = Buy_Sell ~ ., data = Training_data_classification)
library(FSelector)
library(FSelector)
library(FSelector)
library(rJava)
Sys.setenv(JAVA_HOME='C:\\Program Files\\Java\\jre7') # for 64-bit version
library(rJava)
Sys.setenv(JAVA_HOME='C:\\Program Files (x86)\\Java\\jre1.8.0_111') # for 64-bit version
library(rJava)
library(FSelector)
features_information.gain_classification <- information.gain(formula = Buy_Sell ~ ., data = Training_data_classification)
features_gain.ratio_classification <- gain.ratio(formula = Buy_Sell ~ ., data = Training_data_classification)
features_randomForest <- random.forest.importance(formula = Buy_Sell ~ ., data = Training_data_classification, importance.type = 1)
sapply(Training_data_classification, function(x) class(x))
context_var <- c("Symbol", "Year",  "Date",
"HasOptions", "SharkGrouping", "NumberHolders", "SharesOutstanding", "FSPermSecId")
Y_var_potential <- grep(pattern = "Position", x = names(data.set3), value = TRUE)
Y_var <- "Position_change"
X_var <-  setdiff(names(data.set3),
union(Y_var_potential, context_var))
# Identification of Training & Testing data set ------
# Random Sample vs Specific years for training set
RANDOM_TRAINING <- FALSE
FRACTION_TRAINING <- 0.75
if(RANDOM_TRAINING == TRUE) {
n_samples <- floor(NROW(data.set3) * FRACTION_TRAINING)
sample_ids <- sample.int(n = NROW(data.set3), size = n_samples, replace = FALSE)
Training_data_regression <- data.set3[sample_ids , c(Y_var, X_var)]
Test_data_regression     <- data.set3[-sample_ids, c(Y_var, X_var)]
} else {
# Splitting training/Testing
Years_dataset <- as.numeric(sort(unique(data.set3$Year)))
Test_years <- c(2015)
Training_years <- setdiff(Years_dataset, Test_years)
Training_data_regression <- dplyr::filter(data.set3, Year %in% Training_years) %>%
dplyr::select_(.dots = c(Y_var, X_var))
Test_data_regression <- dplyr::filter(data.set3, Year %in% Test_years) %>%
dplyr::select_(.dots = c(Y_var, X_var))
}
# Classification data sets -----
Training_data_classification <- Training_data_regression
Training_data_classification$Buy_Sell <- as.factor(ifelse(Training_data_regression[,Y_var] > 0, "Buy", "Sell"))
Training_data_classification <- Training_data_classification[, -which(names(Training_data_classification) == Y_var)]
Test_data_classification <- Test_data_regression
Test_data_classification$Buy_Sell <- as.factor(ifelse(Test_data_regression[,Y_var] > 0, "Buy", "Sell"))
Test_data_classification <- Test_data_classification[, -which(names(Test_data_classification) == Y_var)]
features_information.gain_classification <- information.gain(formula = Buy_Sell ~ ., data = Training_data_classification)
features_gain.ratio_classification <- gain.ratio(formula = Buy_Sell ~ ., data = Training_data_classification)
features_randomForest <- random.forest.importance(formula = Buy_Sell ~ ., data = Training_data_classification, importance.type = 1)
View(features_randomForest)
View(features_gain.ratio_classification)
View(features_information.gain_classification)
install.packages("rmarkdown")
names(Training_data_classification)
head(data.set3)
library(RMySQL)
con <- dbConnect(RMySQL::MySQL(),  default.file = "~/.my.cnf", group = "local_intel")
dbListTables(con)
data.set <- dbReadTable(con, "SharkPositions_good") %>% dplyr::mutate(Date = as.Date(Date))
tbls_list <- dbListTables(con)
counter <- 0
pryr::mem_used()
library(data.table)
library(bit64)
sec_ticker_exchange <- fread("~/R_workspaces/AI_Targetting/Data from Rob/h_security_ticker_exchange.txt", "|")
write.csv(sec_ticker_exchange, "security_ticker_exchange.csv", row.names = FALSE)
library(data.table)
library(bit64)
DT <- fread("~/R_workspaces/AI_Targetting/own_13f_holdings_hist_1.txt", sep = "|")
#DT <- DT[, ReportingDate := as.Date(REPORT_DATE)]
#pryr::mem_used()
#library(RMySQL)
#con <- dbConnect(RMySQL::MySQL(),  default.file = "~/.my.cnf", group = "local_intel")
#dbWriteTable(con, "Inst_Holdings_hist", DT)
sec_ticker_exchange <- fread("~/R_workspaces/AI_Targetting/Data from Rob/h_security_ticker_exchange.txt", "|")
#dbWriteTable(con, "sec_ticker_exchange", sec_ticker_exchange)
DT2 <- dplyr::left_join(DT,
dplyr::select(sec_ticker_exchange, TICKER_EXCHANGE, FREF_SECURITY_TYPE, FS_PERM_SEC_ID),
by = "FS_PERM_SEC_ID")
DT3 <- DT2 %>% dplyr::rowwise() %>%
dplyr::mutate(Symbol_tmp = ifelse(grepl(pattern = "-", x = TICKER_EXCHANGE),
strsplit(TICKER_EXCHANGE, split = "-")[[1]],
TICKER_EXCHANGE),
Symbol = ifelse(grepl(pattern = ".", x = Symbol_tmp),
strsplit(Symbol_tmp, split = "-")[[1]],
Symbol_tmp)) %>%
dplyr::ungroup() %>% dplyr::select(-Symbol_tmp)
saveRDS(DT3, "security_ticker_exchange.RDS")
rm(DT)
rm(DT2)
gc()
detach("data.table")                                  # detaching the package
detach("package:data.table", unload=TRUE)
remove.packages("data.table")                         # First remove the current version
install.packages("data.table", type = "source",
repos = "http://Rdatatable.github.io/data.table") # Then install devel version
library(data.table)
library(data.table)
data.table::fwrite(DT3, "security_ticker_exchange_with_symbols.csv")
con <- dbConnect(RMySQL::MySQL(),  default.file = "~/.my.cnf", group = "local_intel")
library(RMySQL)
con <- dbConnect(RMySQL::MySQL(),  default.file = "~/.my.cnf", group = "local_intel")
class(DT3$REPORT_DATE)
DT3 <- DT3[, ReportingDate := as.Date(REPORT_DATE)]
library(data.table)
library(bit64)
DT <- fread("~/R_workspaces/AI_Targetting/own_13f_holdings_hist_1.txt", sep = "|")
DT$REPORT_DATE <- as.Date(DT$REPORT_DATE)
sec_ticker_exchange <- fread("~/R_workspaces/AI_Targetting/Data from Rob/h_security_ticker_exchange.txt", "|")
#dbWriteTable(con, "sec_ticker_exchange", sec_ticker_exchange)
DT2 <- dplyr::left_join(DT,
dplyr::select(sec_ticker_exchange, TICKER_EXCHANGE, FREF_SECURITY_TYPE, FS_PERM_SEC_ID),
by = "FS_PERM_SEC_ID")
DT2 <- DT2 %>% dplyr::rowwise() %>%
dplyr::mutate(Symbol_tmp = ifelse(grepl(pattern = "-", x = TICKER_EXCHANGE),
strsplit(TICKER_EXCHANGE, split = "-")[[1]],
TICKER_EXCHANGE),
Symbol = ifelse(grepl(pattern = ".", x = Symbol_tmp),
strsplit(Symbol_tmp, split = ".")[[1]],
Symbol_tmp)) %>%
dplyr::ungroup() %>% dplyr::select(-Symbol_tmp)
# Writting results to disk using fwrite
# https://www.r-bloggers.com/fast-csv-writing-for-r/
#detach("package:data.table", unload=TRUE)             # detaching the package
#remove.packages("data.table")                         # First remove the current version
#install.packages("data.table", type = "source",
#                 repos = "http://Rdatatable.github.io/data.table") # Then install devel version
data.table::fwrite(DT2, "security_ticker_exchange_with_symbols.csv")
#DT3 <- DT3[, ReportingDate := as.Date(REPORT_DATE)]
dbWriteTable(con, "Inst_Holdings_hist_w_symbols", DT2)
symbol_SIC_Groups <- read_csv("~/R_workspaces/AI_Targetting/Data from Rob/symbolSICGroups.csv")
names(symbol_SIC_Groups)[-1] <- paste0("SIC_", names(symbol_SIC_Groups)[-1])
<<<<<<< HEAD
DT3 <- dplyr::left_join(DT2, symbol_SIC_Groups, by = "Symbol")
library(RMySQL)
con <- dbConnect(RMySQL::MySQL(),  default.file = "~/.my.cnf", group = "local_intel")
dbWriteTable(con, "Inst_Holdings_hist_w_symbols", DT2)
symbol_SIC_Groups <- readr::read_csv("~/R_workspaces/AI_Targetting/Data from Rob/symbolSICGroups.csv")
names(symbol_SIC_Groups)[-1] <- paste0("SIC_", names(symbol_SIC_Groups)[-1])
DT3 <- dplyr::left_join(DT2, symbol_SIC_Groups, by = "Symbol")
View(DT3)
head(DT2)
DT2 <- dplyr::left_join(DT,
dplyr::select(sec_ticker_exchange, TICKER_EXCHANGE, FREF_SECURITY_TYPE, FS_PERM_SEC_ID),
by = "FS_PERM_SEC_ID")
tt <- DT2[1:10000] %>% dplyr::rowwise() %>%
dplyr::mutate(Symbol_tmp = ifelse(grepl(pattern = "-", x = TICKER_EXCHANGE),
strsplit(TICKER_EXCHANGE, split = "-")[[1]],
TICKER_EXCHANGE),
Symbol = ifelse(grepl(pattern = ".", x = Symbol_tmp,fixed = TRUE),
strsplit(Symbol_tmp, split = ".")[[1]],
Symbol_tmp)) %>%
dplyr::ungroup() %>% dplyr::select(-Symbol_tmp)
tt <- DT2[1:10000,] %>% dplyr::rowwise() %>%
dplyr::mutate(Symbol_tmp = ifelse(grepl(pattern = "-", x = TICKER_EXCHANGE),
strsplit(TICKER_EXCHANGE, split = "-")[[1]],
TICKER_EXCHANGE),
Symbol = ifelse(grepl(pattern = ".", x = Symbol_tmp,fixed = TRUE),
strsplit(Symbol_tmp, split = ".")[[1]],
Symbol_tmp)) %>%
dplyr::ungroup() %>% dplyr::select(-Symbol_tmp)
View(tt)
tt2 <- "FDC.XX2-NYS"
grepl(pattern = "-", x = tt2)
tt3 <- strsplit(tt2, split = "-")[[1]]
tt3
tt3 <- strsplit(tt2, split = "-")[1]
tt3
tt3 <- strsplit(tt2, split = "-")
tt3
tt3 <- unlist(strsplit(tt2, split = "-"))[1]
tt3
class(tt3)
tt <- DT2[1:10000,] %>% dplyr::rowwise() %>%
dplyr::mutate(Symbol_tmp = ifelse(grepl(pattern = "-", x = TICKER_EXCHANGE),
unlist(strsplit(TICKER_EXCHANGE, split = "-", fixed = TRUE))[1],
TICKER_EXCHANGE),
Symbol = ifelse(grepl(pattern = ".", x = Symbol_tmp,fixed = TRUE),
unlist(strsplit(Symbol_tmp, split = ".", fixed = TRUE))[1],
Symbol_tmp)) %>%
dplyr::ungroup() %>% dplyr::select(-Symbol_tmp)
View(tt)
rm(tt)
rm(tt2)
rm(tt3)
library(dplyr)
library(multidplyr)
cluster <- create_cluster(7)
set_default_cluster(cluster)
DT3 <- DT2 %>% partition() %>%
mutate(Symbol_tmp = ifelse(grepl(pattern = "-", x = TICKER_EXCHANGE),
unlist(strsplit(TICKER_EXCHANGE, split = "-", fixed = TRUE))[1],
TICKER_EXCHANGE),
Symbol = ifelse(grepl(pattern = ".", x = Symbol_tmp,fixed = TRUE),
unlist(strsplit(Symbol_tmp, split = ".", fixed = TRUE))[1],
Symbol_tmp)) %>%
collect()
View(DT3)
DT3
DT3 <- DT2 %>% partition() %>% rowwise() %>%
mutate(Symbol_tmp = ifelse(grepl(pattern = "-", x = TICKER_EXCHANGE),
unlist(strsplit(TICKER_EXCHANGE, split = "-", fixed = TRUE))[1],
TICKER_EXCHANGE),
Symbol = ifelse(grepl(pattern = ".", x = Symbol_tmp,fixed = TRUE),
unlist(strsplit(Symbol_tmp, split = ".", fixed = TRUE))[1],
Symbol_tmp)) %>%
collect()
detach("package:dplyr", unload=TRUE)
detach("package:multidplyr", unload=TRUE)
library("dplyr", lib.loc="~/R/win-library/3.3")
detach("package:dplyr", unload=TRUE)
library(data.table)
DT3 <- DT2 %>% dplyr::rowwise() %>%
dplyr::mutate(Symbol_tmp = ifelse(grepl(pattern = "-", x = TICKER_EXCHANGE),
unlist(strsplit(TICKER_EXCHANGE, split = "-", fixed = TRUE))[1],
TICKER_EXCHANGE),
Symbol = ifelse(grepl(pattern = ".", x = Symbol_tmp,fixed = TRUE),
unlist(strsplit(Symbol_tmp, split = ".", fixed = TRUE))[1],
Symbol_tmp)) %>%
dplyr::ungroup() %>% dplyr::select(-Symbol_tmp)
View(DT3)
data.table::fwrite(DT3, "security_ticker_exchange_with_symbols.csv")
symbol_SIC_Groups <- readr::read_csv("~/R_workspaces/AI_Targetting/Data from Rob/symbolSICGroups.csv")
names(symbol_SIC_Groups)[-1] <- paste0("SIC_", names(symbol_SIC_Groups)[-1])
DT4 <- dplyr::left_join(DT3, symbol_SIC_Groups, by = "Symbol")
View(DT4)
tt <- dplyr::filter(DT4, is.na(SIC_Group1))
View(tt)
length(unique(tt$TICKER_EXCHANGE))
length(unique(tt$Symbol))
View(symbol_SIC_Groups)
names(DT3)
dbWriteTable(con, "Inst_Holdings_hist_w_symbols", DT3)
tt <- DT2[1:1000,]
ttt <- dplyr::filter(DT4, is.na(SIC_Group1), grepl(pattern = "(-NYS)|(-NAS)", x = TICKER_EXCHANGE) )
View(ttt)
View(symbol_SIC_Groups)
length(unique(ttt$TICKER_EXCHANGE))
ttt2 <- dplyr::filter(DT4, !is.na(SIC_Group1), grepl(pattern = "(-NYS)|(-NAS)", x = TICKER_EXCHANGE) )
length(unique(ttt2$Symbol))
length(unique(ttt2$TICKER_EXCHANGE))
rm(data.set3)
rm(tt)
rm(ttt)
rm(ttt2)
rm(Training_data_regression)
rm(Test_data_regression)
own_basic <- fread("~/R_workspaces/AI_Targetting/Data from Rob/own_basic.txt", "|")
edm_standard_entity <- fread("~/R_workspaces/AI_Targetting/Data from Rob/edm_standard_entity.txt", "|")
View(own_basic)
names(own_basic)
names(DT3)
names(edm_standard_entity)
View(edm_standard_entity)
DT4 <- dplyr::left_join(DT3,
dplyr::select(own_basic, FS_PERM_SEC_ID, Company = FACTSET_ENTITY_ID, ISSUE_TYPE, CAP_GROUP),
by = "FS_PERM_SEC_ID")
View(DT4)
DT5 <- dplyr::left_join(DT4,
dplyr::select(edm_standard_entity, PRIMARY_SIC_CODE, Company = FACTSET_ENTITY_ID,
PRIMARY_SIC_CODE, INDUSTRY_CODE, SECTOR_CODE),
by = "Company")
View(DT5)
help(memory.size)
memory.size()
View(DT5)
rm(DT)
View(DT5)
rm(symbol_SIC_Groups)
saveRDS(DT5, "own_inst_enriched.RDS")
gc()
ls()
library(data.table)
library(bit64)
library(data.table)
library(bit64)
DT1.1 <- fread("~/R_workspaces/AI_Targetting/own_fund/own_fund_holdings_hist_1.txt", sep = "|")
sec_ticker_exchange <- fread("~/R_workspaces/AI_Targetting/Data from Rob/h_security_ticker_exchange.txt", "|")
DT2.1 <- dplyr::left_join(DT1.1,
dplyr::select(sec_ticker_exchange, TICKER_EXCHANGE, FREF_SECURITY_TYPE, FS_PERM_SEC_ID),
by = "FS_PERM_SEC_ID")
=======
names(symbol_SIC_Groups)
tt <- dplyr::left_join(tt, symbol_SIC_Groups, by = "Symbol")
tt2 <- dplyr::filter(tt, is.na(SIC_Group1))
NROW(tt2)
View(tt2)
NROW(tt2)/NROW(tt)
tt3 <- dplyr::filter(tt, grepl(pattern = ".", x = Symbol, fixed = TRUE))
View(tt3)
NROW(tt3)
NROW(tt2)
=======
>>>>>>> 2b3418d1753248fd484b43dfc614f72040f4fb2b
>>>>>>> 0c484179b03a9984cb4a73d42a5e6d8bb53378ce
>>>>>>> 24a3fe80a629ed7915a6998dfa68630637e404de
>>>>>>> e7caf8b09f42bcef33a8a796ced2a905076b8d82
