<<<<<<< HEAD
=======
<<<<<<< HEAD
=======
<<<<<<< HEAD
model_tt1 <- robustbase::glmrob(Buy_Sell ~ ., family=binomial(), data = Training_data_classification)
model_tt2 <- robustbase::glmrob(Buy_Sell ~ ., family=binomial(), data = Training_data_classification, weights.on.x = "robCov")
# 3.2 Bias reduction in binomial-response generalized linear models: brglm package
# penalized likelihood where penalization is by Jeffreys invariant prior.
m_Logit_BiasRedution <- brglm::brglm(Buy_Sell ~ ., family = binomial(), data = Training_data_classification)
# 3.3 Baysian GLM
m_Logit_Bayesian <- arm::bayesglm(Buy_Sell ~ ., family=binomial(link="probit"), data = Training_data_classification)
# 4) Trying smaller model by utilizing the bestglm package -----
# https://rstudio-pubs-static.s3.amazonaws.com/2897_9220b21cfc0c43a396ff9abf122bb351.html
# http://www2.uaem.mx/r-mirror/web/packages/bestglm/vignettes/bestglm.pdf
Xy <- cbind(Training_data_classification[,which(names(Training_data_classification) != "Buy_Sell")],
Bell_Sell = Training_data_classification[,"Buy_Sell"])
# Produced error: Error in rep(-Inf, 2^p) : invalid 'times' argument
best_glm_binomial_probit <- bestglm::bestglm(Xy, family=binomial(link="probit"), method = "forward")
# http://stackoverflow.com/questions/12012746/bestglm-alternatives-for-dataset-with-many-variables
rm(Xy)
# 5) Smaller subset of predictor using the glmnet package ------
# ref:
# http://stats.stackexchange.com/questions/77546/how-to-interpret-glmnet
# https://web.stanford.edu/~hastie/Papers/Glmnet_Vignette.pdf
>>>>>>> 24a3fe80a629ed7915a6998dfa68630637e404de
#
# Predicted Buy/Sell given Buy/Sell
Prob_pred_Buy_given_Buy_Lasso   = paste(round(100 * sum(pred_Buy_given_Buy_Lasso == TRUE)  /Count_Buy,digits = 2),"%"),
Prob_pred_Buy_given_Sell_Lasso  = paste(round(100 * sum(pred_Buy_given_Sell_Lasso == TRUE) /Count_Sell,digits = 2),"%"),
Prob_pred_Sell_given_Buy_Lasso  = paste(round(100 * sum(pred_Sell_given_Buy_Lasso == TRUE) /Count_Buy,digits = 2),"%"),
Prob_pred_Sell_given_Sell_Lasso = paste(round(100 * sum(pred_Sell_given_Sell_Lasso == TRUE)/Count_Sell,digits = 2),"%"),
# Buy/Sell given Predicted Buy/Sell
Prob_Buy_given_pred_Buy_Lasso   = paste(round(100 * sum(Buy_given_Pred_Buy_Lasso == TRUE)  /sum(pred_glmnet_lasso_Buy_Sell == "Buy" ),digits = 2),"%"),
Prob_Buy_given_pred_Sell_Lasso  = paste(round(100 * sum(Buy_given_Pred_Sell_Lasso == TRUE) /sum(pred_glmnet_lasso_Buy_Sell == "Sell"),digits = 2),"%"),
Prob_Sell_given_pred_Buy_Lasso  = paste(round(100 * sum(Sell_given_Pred_Buy_Lasso == TRUE) /sum(pred_glmnet_lasso_Buy_Sell == "Buy" ),digits = 2),"%"),
Prob_Sell_given_pred_Sell_Lasso = paste(round(100 * sum(Sell_given_Pred_Sell_Lasso == TRUE)/sum(pred_glmnet_lasso_Buy_Sell == "Sell"),digits = 2),"%"),
# Accuracy
Pred_Accuracy_GLMnet_Lasso      = paste(round(100 * sum(Correct_pred_GLMnet_Lasso == TRUE) /Count,digits = 2),"%")) %>% as.vector()
Results <- cbind(fund = f, Results)
# Saving model to disk for future use
outCon <- file(paste0(save.model.path,f,".txt"), "w")
model.char <- rawToChar(serialize(glmnet_lasso, NULL, ascii=T))
cat(model.char, file=outCon); close(outCon)
return(Results)
}
getwd()
save.model.path <- "./ModelResults/"
for(f in funds_ids$FACTSET_FUND_ID) {
message(paste0("Processing fund:", f ,". Memory used: ", pryr::mem_used()))
qry <- paste0("SELECT * FROM fund_us_holdings_hist_w_symbols_and_sic where FACTSET_FUND_ID = '",f , "'")
data.set <- dbGetQuery(con, qry)
data.set <- data.set %>%
dplyr::mutate(Q_Ends = as.Date(timeDate::timeLastDayInQuarter(REPORT_DATE, format = "%Y-%m-%d", zone = "", FinCenter = "")),
HOLDING = as.numeric(HOLDING)) %>%
dplyr::group_by(FACTSET_FUND_ID, TICKER_EXCHANGE, Q_Ends) %>%
dplyr::summarise(HOLDING_tot = sum(HOLDING, na.rm = TRUE),
Symbol = dplyr::first(Symbol),
CAP_GROUP = as.factor(dplyr::first(CAP_GROUP)),
SECTOR_CODE = as.factor(dplyr::first(SECTOR_CODE))
) %>% dplyr::ungroup() %>%
# Enriching the ownership data with the fundamental data of the company
dplyr::left_join(Fundamental_data, by = c("Symbol", "Q_Ends")) %>%
dplyr::group_by(Symbol) %>% dplyr::arrange(Q_Ends) %>%
dplyr::mutate(HOLDING_chng = HOLDING_tot - lag(HOLDING_tot),
Buy_Sell = as.factor(ifelse(HOLDING_chng < 0, "Sell", "Buy"))) %>%
dplyr::ungroup() %>% dplyr::arrange(Symbol, Q_Ends)
# Specifying the regression variables
data.set <- na.omit(data.set) %>%
# Eliminating context (uneccessary) variable
dplyr::select(-FACTSET_FUND_ID, -TICKER_EXCHANGE, -Q_Ends, -HOLDING_tot, -Symbol)
Y_Var <- "Buy_Sell"
X_Var <-  setdiff(names(data.set), Y_Var)
# Splitting the data_set into training and testing set based on proportion variable
n_samples <- floor(NROW(data.set) * FRACTION_TRAINING)
sample_ids <- sample.int(n = NROW(data.set), size = n_samples, replace = FALSE)
Training_data <- data.set[sample_ids , c(Y_Var, X_Var)]
Test_data     <- data.set[-sample_ids, c(Y_Var, X_Var)]
X <- model.matrix( ~ .-1, data = Training_data[, X_Var])
Y <- as.numeric(Training_data[[Y_Var]])
# Cross validation for hyper-parameter estimation
N_folds <- 10
fold_id <- sample(1:N_folds,size=length(Y),replace=TRUE)
glmnet_lasso <- glmnet::cv.glmnet(X,Y, intercept=FALSE, foldid=fold_id, alpha=1, family = "binomial", type.measure="class") ## lasso regression - Sparse coeff
# Determine the optimal probability thereshold value to determine the class (buy vs sell)
# https://hopstat.wordpress.com/2014/12/19/a-small-introduction-to-the-rocr-package/
# Logit model
pred_logit <- prediction(predictions = predict(glmnet_lasso,
newx = model.matrix( ~ .-1, data = Training_data[, X_Var]),
# as.matrix(Training_data[,which(names(Training_data_classification) != "Buy_Sell")]),
s = "lambda.min", type = "response"),
labels = Training_data[, Y_Var])
# Equal cost for FP and FN
cost.perf  <- performance(pred_logit, "cost", cost.fp = 1, cost.fn = 1)
opt_threshold <- pred_logit@cutoffs[[1]][which.min(cost.perf@y.values[[1]])]
# Determining Predictive accuracy -----
X_test <- model.matrix( ~ .-1, data = Test_data[, X_Var])
Test_data$Y_prob <- predict(glmnet_lasso, s='lambda.min', newx=X_test, type="response")  %>% as.vector()
Test_data$pred_glmnet_lasso_Buy_Sell <- ifelse(Y_prob > opt_threshold, "Sell", "Buy")
# Creating Results data.frame
Results <- Test_data %>% dplyr::mutate(
# Predicted Buy/Sell given Buy/Sell
pred_Buy_given_Buy_Lasso    = ifelse(pred_glmnet_lasso_Buy_Sell == "Buy"  & Buy_Sell == "Buy" , TRUE, FALSE),
pred_Buy_given_Sell_Lasso   = ifelse(pred_glmnet_lasso_Buy_Sell == "Buy"  & Buy_Sell == "Sell", TRUE, FALSE),
pred_Sell_given_Buy_Lasso   = ifelse(pred_glmnet_lasso_Buy_Sell == "Sell" & Buy_Sell == "Buy" , TRUE, FALSE),
pred_Sell_given_Sell_Lasso  = ifelse(pred_glmnet_lasso_Buy_Sell == "Sell" & Buy_Sell == "Sell", TRUE, FALSE),
## Buy/Sell given Predicted Buy/Sell
Buy_given_Pred_Buy_Lasso   = ifelse(Buy_Sell == "Buy"  & pred_glmnet_lasso_Buy_Sell == "Buy" , TRUE, FALSE),
Buy_given_Pred_Sell_Lasso  = ifelse(Buy_Sell == "Buy"  & pred_glmnet_lasso_Buy_Sell == "Sell", TRUE, FALSE),
Sell_given_Pred_Buy_Lasso  = ifelse(Buy_Sell == "Sell" & pred_glmnet_lasso_Buy_Sell == "Buy" , TRUE, FALSE),
Sell_given_Pred_Sell_Lasso = ifelse(Buy_Sell == "Sell" & pred_glmnet_lasso_Buy_Sell == "Sell", TRUE, FALSE),
# Accuracy
Correct_pred_GLMnet_Lasso   = ifelse(pred_glmnet_lasso_Buy_Sell == Buy_Sell, TRUE, FALSE)
) %>% dplyr::summarise(
# TestData statistics
Count = as.integer(n()),
Count_Buy  = as.integer(sum(Buy_Sell == "Buy")),
Count_Sell = as.integer(sum(Buy_Sell == "Sell")),
Percent_buy = paste(round(100 * Count_Buy/Count, digits = 2), "%"),
Percent_sell =  paste(round(100 * Count_Sell/Count,digits = 2), "%"),
# GLMnet Lasso
# ============
#
# Predicted Buy/Sell given Buy/Sell
Prob_pred_Buy_given_Buy_Lasso   = paste(round(100 * sum(pred_Buy_given_Buy_Lasso == TRUE)  /Count_Buy,digits = 2),"%"),
Prob_pred_Buy_given_Sell_Lasso  = paste(round(100 * sum(pred_Buy_given_Sell_Lasso == TRUE) /Count_Sell,digits = 2),"%"),
Prob_pred_Sell_given_Buy_Lasso  = paste(round(100 * sum(pred_Sell_given_Buy_Lasso == TRUE) /Count_Buy,digits = 2),"%"),
Prob_pred_Sell_given_Sell_Lasso = paste(round(100 * sum(pred_Sell_given_Sell_Lasso == TRUE)/Count_Sell,digits = 2),"%"),
# Buy/Sell given Predicted Buy/Sell
Prob_Buy_given_pred_Buy_Lasso   = paste(round(100 * sum(Buy_given_Pred_Buy_Lasso == TRUE)  /sum(pred_glmnet_lasso_Buy_Sell == "Buy" ),digits = 2),"%"),
Prob_Buy_given_pred_Sell_Lasso  = paste(round(100 * sum(Buy_given_Pred_Sell_Lasso == TRUE) /sum(pred_glmnet_lasso_Buy_Sell == "Sell"),digits = 2),"%"),
Prob_Sell_given_pred_Buy_Lasso  = paste(round(100 * sum(Sell_given_Pred_Buy_Lasso == TRUE) /sum(pred_glmnet_lasso_Buy_Sell == "Buy" ),digits = 2),"%"),
Prob_Sell_given_pred_Sell_Lasso = paste(round(100 * sum(Sell_given_Pred_Sell_Lasso == TRUE)/sum(pred_glmnet_lasso_Buy_Sell == "Sell"),digits = 2),"%"),
# Accuracy
Pred_Accuracy_GLMnet_Lasso      = paste(round(100 * sum(Correct_pred_GLMnet_Lasso == TRUE) /Count,digits = 2),"%")) %>% as.vector()
Results <- cbind(fund = f, Results)
# Saving model to disk for future use
outCon <- file(paste0(save.model.path,f,".txt"), "w")
model.char <- rawToChar(serialize(glmnet_lasso, NULL, ascii=T))
cat(model.char, file=outCon); close(outCon)
return(Results)
}
counter <- 0  # about 49 tables to process
FRACTION_TRAINING <- 0.75
save.model.path <- "./ModelResults/"
Results_final <- list()
for(f in funds_ids$FACTSET_FUND_ID) {
counter <<- counter + 1
message(paste0("Processing fund:", f ,". Memory used: ", pryr::mem_used()))
qry <- paste0("SELECT * FROM fund_us_holdings_hist_w_symbols_and_sic where FACTSET_FUND_ID = '",f , "'")
data.set <- dbGetQuery(con, qry)
data.set <- data.set %>%
dplyr::mutate(Q_Ends = as.Date(timeDate::timeLastDayInQuarter(REPORT_DATE, format = "%Y-%m-%d", zone = "", FinCenter = "")),
HOLDING = as.numeric(HOLDING)) %>%
dplyr::group_by(FACTSET_FUND_ID, TICKER_EXCHANGE, Q_Ends) %>%
dplyr::summarise(HOLDING_tot = sum(HOLDING, na.rm = TRUE),
Symbol = dplyr::first(Symbol),
CAP_GROUP = as.factor(dplyr::first(CAP_GROUP)),
SECTOR_CODE = as.factor(dplyr::first(SECTOR_CODE))
) %>% dplyr::ungroup() %>%
# Enriching the ownership data with the fundamental data of the company
dplyr::left_join(Fundamental_data, by = c("Symbol", "Q_Ends")) %>%
dplyr::group_by(Symbol) %>% dplyr::arrange(Q_Ends) %>%
dplyr::mutate(HOLDING_chng = HOLDING_tot - lag(HOLDING_tot),
Buy_Sell = as.factor(ifelse(HOLDING_chng < 0, "Sell", "Buy"))) %>%
dplyr::ungroup() %>% dplyr::arrange(Symbol, Q_Ends)
# Specifying the regression variables
data.set <- na.omit(data.set) %>%
# Eliminating context (uneccessary) variable
dplyr::select(-FACTSET_FUND_ID, -TICKER_EXCHANGE, -Q_Ends, -HOLDING_tot, -Symbol)
Y_Var <- "Buy_Sell"
X_Var <-  setdiff(names(data.set), Y_Var)
# Splitting the data_set into training and testing set based on proportion variable
n_samples <- floor(NROW(data.set) * FRACTION_TRAINING)
sample_ids <- sample.int(n = NROW(data.set), size = n_samples, replace = FALSE)
Training_data <- data.set[sample_ids , c(Y_Var, X_Var)]
Test_data     <- data.set[-sample_ids, c(Y_Var, X_Var)]
X <- model.matrix( ~ .-1, data = Training_data[, X_Var])
Y <- as.numeric(Training_data[[Y_Var]])
# Cross validation for hyper-parameter estimation
N_folds <- 10
fold_id <- sample(1:N_folds,size=length(Y),replace=TRUE)
glmnet_lasso <- glmnet::cv.glmnet(X,Y, intercept=FALSE, foldid=fold_id, alpha=1, family = "binomial", type.measure="class") ## lasso regression - Sparse coeff
# Determine the optimal probability thereshold value to determine the class (buy vs sell)
# https://hopstat.wordpress.com/2014/12/19/a-small-introduction-to-the-rocr-package/
# Logit model
pred_logit <- prediction(predictions = predict(glmnet_lasso,
newx = model.matrix( ~ .-1, data = Training_data[, X_Var]),
# as.matrix(Training_data[,which(names(Training_data_classification) != "Buy_Sell")]),
s = "lambda.min", type = "response"),
labels = Training_data[, Y_Var])
# Equal cost for FP and FN
cost.perf  <- performance(pred_logit, "cost", cost.fp = 1, cost.fn = 1)
opt_threshold <- pred_logit@cutoffs[[1]][which.min(cost.perf@y.values[[1]])]
# Determining Predictive accuracy -----
X_test <- model.matrix( ~ .-1, data = Test_data[, X_Var])
Test_data$Y_prob <- predict(glmnet_lasso, s='lambda.min', newx=X_test, type="response")  %>% as.vector()
Test_data$pred_glmnet_lasso_Buy_Sell <- ifelse(Y_prob > opt_threshold, "Sell", "Buy")
# Creating Results data.frame
Results <- Test_data %>% dplyr::mutate(
# Predicted Buy/Sell given Buy/Sell
pred_Buy_given_Buy_Lasso    = ifelse(pred_glmnet_lasso_Buy_Sell == "Buy"  & Buy_Sell == "Buy" , TRUE, FALSE),
pred_Buy_given_Sell_Lasso   = ifelse(pred_glmnet_lasso_Buy_Sell == "Buy"  & Buy_Sell == "Sell", TRUE, FALSE),
pred_Sell_given_Buy_Lasso   = ifelse(pred_glmnet_lasso_Buy_Sell == "Sell" & Buy_Sell == "Buy" , TRUE, FALSE),
pred_Sell_given_Sell_Lasso  = ifelse(pred_glmnet_lasso_Buy_Sell == "Sell" & Buy_Sell == "Sell", TRUE, FALSE),
## Buy/Sell given Predicted Buy/Sell
Buy_given_Pred_Buy_Lasso   = ifelse(Buy_Sell == "Buy"  & pred_glmnet_lasso_Buy_Sell == "Buy" , TRUE, FALSE),
Buy_given_Pred_Sell_Lasso  = ifelse(Buy_Sell == "Buy"  & pred_glmnet_lasso_Buy_Sell == "Sell", TRUE, FALSE),
Sell_given_Pred_Buy_Lasso  = ifelse(Buy_Sell == "Sell" & pred_glmnet_lasso_Buy_Sell == "Buy" , TRUE, FALSE),
Sell_given_Pred_Sell_Lasso = ifelse(Buy_Sell == "Sell" & pred_glmnet_lasso_Buy_Sell == "Sell", TRUE, FALSE),
# Accuracy
Correct_pred_GLMnet_Lasso   = ifelse(pred_glmnet_lasso_Buy_Sell == Buy_Sell, TRUE, FALSE)
) %>% dplyr::summarise(
# TestData statistics
Count = as.integer(n()),
Count_Buy  = as.integer(sum(Buy_Sell == "Buy")),
Count_Sell = as.integer(sum(Buy_Sell == "Sell")),
Percent_buy = paste(round(100 * Count_Buy/Count, digits = 2), "%"),
Percent_sell =  paste(round(100 * Count_Sell/Count,digits = 2), "%"),
# GLMnet Lasso
# ============
#
# Predicted Buy/Sell given Buy/Sell
Prob_pred_Buy_given_Buy_Lasso   = paste(round(100 * sum(pred_Buy_given_Buy_Lasso == TRUE)  /Count_Buy,digits = 2),"%"),
Prob_pred_Buy_given_Sell_Lasso  = paste(round(100 * sum(pred_Buy_given_Sell_Lasso == TRUE) /Count_Sell,digits = 2),"%"),
Prob_pred_Sell_given_Buy_Lasso  = paste(round(100 * sum(pred_Sell_given_Buy_Lasso == TRUE) /Count_Buy,digits = 2),"%"),
Prob_pred_Sell_given_Sell_Lasso = paste(round(100 * sum(pred_Sell_given_Sell_Lasso == TRUE)/Count_Sell,digits = 2),"%"),
# Buy/Sell given Predicted Buy/Sell
Prob_Buy_given_pred_Buy_Lasso   = paste(round(100 * sum(Buy_given_Pred_Buy_Lasso == TRUE)  /sum(pred_glmnet_lasso_Buy_Sell == "Buy" ),digits = 2),"%"),
Prob_Buy_given_pred_Sell_Lasso  = paste(round(100 * sum(Buy_given_Pred_Sell_Lasso == TRUE) /sum(pred_glmnet_lasso_Buy_Sell == "Sell"),digits = 2),"%"),
Prob_Sell_given_pred_Buy_Lasso  = paste(round(100 * sum(Sell_given_Pred_Buy_Lasso == TRUE) /sum(pred_glmnet_lasso_Buy_Sell == "Buy" ),digits = 2),"%"),
Prob_Sell_given_pred_Sell_Lasso = paste(round(100 * sum(Sell_given_Pred_Sell_Lasso == TRUE)/sum(pred_glmnet_lasso_Buy_Sell == "Sell"),digits = 2),"%"),
# Accuracy
Pred_Accuracy_GLMnet_Lasso      = paste(round(100 * sum(Correct_pred_GLMnet_Lasso == TRUE) /Count,digits = 2),"%")) %>% as.vector()
Results <- cbind(fund = f, Results)
# Saving model to disk for future use
outCon <- file(paste0(save.model.path,f,".txt"), "w")
model.char <- rawToChar(serialize(glmnet_lasso, NULL, ascii=T))
cat(model.char, file=outCon); close(outCon)
Results_final[[counter]] <- Results
}
for(f in funds_ids$FACTSET_FUND_ID[[2]]) {
counter <<- counter + 1
message(paste0("Processing fund:", f ,". Memory used: ", pryr::mem_used()))
qry <- paste0("SELECT * FROM fund_us_holdings_hist_w_symbols_and_sic where FACTSET_FUND_ID = '",f , "'")
data.set <- dbGetQuery(con, qry)
data.set <- data.set %>%
dplyr::mutate(Q_Ends = as.Date(timeDate::timeLastDayInQuarter(REPORT_DATE, format = "%Y-%m-%d", zone = "", FinCenter = "")),
HOLDING = as.numeric(HOLDING)) %>%
dplyr::group_by(FACTSET_FUND_ID, TICKER_EXCHANGE, Q_Ends) %>%
dplyr::summarise(HOLDING_tot = sum(HOLDING, na.rm = TRUE),
Symbol = dplyr::first(Symbol),
CAP_GROUP = as.factor(dplyr::first(CAP_GROUP)),
SECTOR_CODE = as.factor(dplyr::first(SECTOR_CODE))
) %>% dplyr::ungroup() %>%
# Enriching the ownership data with the fundamental data of the company
dplyr::left_join(Fundamental_data, by = c("Symbol", "Q_Ends")) %>%
dplyr::group_by(Symbol) %>% dplyr::arrange(Q_Ends) %>%
dplyr::mutate(HOLDING_chng = HOLDING_tot - lag(HOLDING_tot),
Buy_Sell = as.factor(ifelse(HOLDING_chng < 0, "Sell", "Buy"))) %>%
dplyr::ungroup() %>% dplyr::arrange(Symbol, Q_Ends)
# Specifying the regression variables
data.set <- na.omit(data.set) %>%
# Eliminating context (uneccessary) variable
dplyr::select(-FACTSET_FUND_ID, -TICKER_EXCHANGE, -Q_Ends, -HOLDING_tot, -Symbol)
Y_Var <- "Buy_Sell"
X_Var <-  setdiff(names(data.set), Y_Var)
# Splitting the data_set into training and testing set based on proportion variable
n_samples <- floor(NROW(data.set) * FRACTION_TRAINING)
sample_ids <- sample.int(n = NROW(data.set), size = n_samples, replace = FALSE)
Training_data <- data.set[sample_ids , c(Y_Var, X_Var)]
Test_data     <- data.set[-sample_ids, c(Y_Var, X_Var)]
X <- model.matrix( ~ .-1, data = Training_data[, X_Var])
Y <- as.numeric(Training_data[[Y_Var]])
# Cross validation for hyper-parameter estimation
N_folds <- 10
fold_id <- sample(1:N_folds,size=length(Y),replace=TRUE)
glmnet_lasso <- glmnet::cv.glmnet(X,Y, intercept=FALSE, foldid=fold_id, alpha=1, family = "binomial", type.measure="class") ## lasso regression - Sparse coeff
# Determine the optimal probability thereshold value to determine the class (buy vs sell)
# https://hopstat.wordpress.com/2014/12/19/a-small-introduction-to-the-rocr-package/
# Logit model
pred_logit <- prediction(predictions = predict(glmnet_lasso,
newx = model.matrix( ~ .-1, data = Training_data[, X_Var]),
# as.matrix(Training_data[,which(names(Training_data_classification) != "Buy_Sell")]),
s = "lambda.min", type = "response"),
labels = Training_data[, Y_Var])
# Equal cost for FP and FN
cost.perf  <- performance(pred_logit, "cost", cost.fp = 1, cost.fn = 1)
opt_threshold <- pred_logit@cutoffs[[1]][which.min(cost.perf@y.values[[1]])]
# Determining Predictive accuracy -----
browser()
X_test <- model.matrix( ~ .-1, data = Test_data[, X_Var])
Test_data$Y_prob <- predict(glmnet_lasso, s='lambda.min', newx=X_test, type="response")  %>% as.vector()
Test_data$pred_glmnet_lasso_Buy_Sell <- ifelse(Y_prob > opt_threshold, "Sell", "Buy")
# Creating Results data.frame
Results <- Test_data %>% dplyr::mutate(
# Predicted Buy/Sell given Buy/Sell
pred_Buy_given_Buy_Lasso    = ifelse(pred_glmnet_lasso_Buy_Sell == "Buy"  & Buy_Sell == "Buy" , TRUE, FALSE),
pred_Buy_given_Sell_Lasso   = ifelse(pred_glmnet_lasso_Buy_Sell == "Buy"  & Buy_Sell == "Sell", TRUE, FALSE),
pred_Sell_given_Buy_Lasso   = ifelse(pred_glmnet_lasso_Buy_Sell == "Sell" & Buy_Sell == "Buy" , TRUE, FALSE),
pred_Sell_given_Sell_Lasso  = ifelse(pred_glmnet_lasso_Buy_Sell == "Sell" & Buy_Sell == "Sell", TRUE, FALSE),
## Buy/Sell given Predicted Buy/Sell
Buy_given_Pred_Buy_Lasso   = ifelse(Buy_Sell == "Buy"  & pred_glmnet_lasso_Buy_Sell == "Buy" , TRUE, FALSE),
Buy_given_Pred_Sell_Lasso  = ifelse(Buy_Sell == "Buy"  & pred_glmnet_lasso_Buy_Sell == "Sell", TRUE, FALSE),
Sell_given_Pred_Buy_Lasso  = ifelse(Buy_Sell == "Sell" & pred_glmnet_lasso_Buy_Sell == "Buy" , TRUE, FALSE),
Sell_given_Pred_Sell_Lasso = ifelse(Buy_Sell == "Sell" & pred_glmnet_lasso_Buy_Sell == "Sell", TRUE, FALSE),
# Accuracy
Correct_pred_GLMnet_Lasso   = ifelse(pred_glmnet_lasso_Buy_Sell == Buy_Sell, TRUE, FALSE)
) %>% dplyr::summarise(
# TestData statistics
Count = as.integer(n()),
Count_Buy  = as.integer(sum(Buy_Sell == "Buy")),
Count_Sell = as.integer(sum(Buy_Sell == "Sell")),
Percent_buy = paste(round(100 * Count_Buy/Count, digits = 2), "%"),
Percent_sell =  paste(round(100 * Count_Sell/Count,digits = 2), "%"),
# GLMnet Lasso
# ============
#
# Predicted Buy/Sell given Buy/Sell
Prob_pred_Buy_given_Buy_Lasso   = paste(round(100 * sum(pred_Buy_given_Buy_Lasso == TRUE)  /Count_Buy,digits = 2),"%"),
Prob_pred_Buy_given_Sell_Lasso  = paste(round(100 * sum(pred_Buy_given_Sell_Lasso == TRUE) /Count_Sell,digits = 2),"%"),
Prob_pred_Sell_given_Buy_Lasso  = paste(round(100 * sum(pred_Sell_given_Buy_Lasso == TRUE) /Count_Buy,digits = 2),"%"),
Prob_pred_Sell_given_Sell_Lasso = paste(round(100 * sum(pred_Sell_given_Sell_Lasso == TRUE)/Count_Sell,digits = 2),"%"),
# Buy/Sell given Predicted Buy/Sell
Prob_Buy_given_pred_Buy_Lasso   = paste(round(100 * sum(Buy_given_Pred_Buy_Lasso == TRUE)  /sum(pred_glmnet_lasso_Buy_Sell == "Buy" ),digits = 2),"%"),
Prob_Buy_given_pred_Sell_Lasso  = paste(round(100 * sum(Buy_given_Pred_Sell_Lasso == TRUE) /sum(pred_glmnet_lasso_Buy_Sell == "Sell"),digits = 2),"%"),
Prob_Sell_given_pred_Buy_Lasso  = paste(round(100 * sum(Sell_given_Pred_Buy_Lasso == TRUE) /sum(pred_glmnet_lasso_Buy_Sell == "Buy" ),digits = 2),"%"),
Prob_Sell_given_pred_Sell_Lasso = paste(round(100 * sum(Sell_given_Pred_Sell_Lasso == TRUE)/sum(pred_glmnet_lasso_Buy_Sell == "Sell"),digits = 2),"%"),
# Accuracy
Pred_Accuracy_GLMnet_Lasso      = paste(round(100 * sum(Correct_pred_GLMnet_Lasso == TRUE) /Count,digits = 2),"%")) %>% as.vector()
Results <- cbind(fund = f, Results)
# Saving model to disk for future use
outCon <- file(paste0(save.model.path,f,".txt"), "w")
model.char <- rawToChar(serialize(glmnet_lasso, NULL, ascii=T))
cat(model.char, file=outCon); close(outCon)
Results_final[[counter]] <- Results
}
dim(Test_data)
Test_data$Y_prob <- predict(glmnet_lasso, s='lambda.min', newx=X_test, type="response")  %>% as.vector()
Test_data$pred_glmnet_lasso_Buy_Sell <- ifelse(Y_prob > opt_threshold, "Sell", "Buy")
for(f in funds_ids$FACTSET_FUND_ID[[2]]) {
counter <<- counter + 1
message(paste0("Processing fund:", f ,". Memory used: ", pryr::mem_used()))
qry <- paste0("SELECT * FROM fund_us_holdings_hist_w_symbols_and_sic where FACTSET_FUND_ID = '",f , "'")
data.set <- dbGetQuery(con, qry)
data.set <- data.set %>%
dplyr::mutate(Q_Ends = as.Date(timeDate::timeLastDayInQuarter(REPORT_DATE, format = "%Y-%m-%d", zone = "", FinCenter = "")),
HOLDING = as.numeric(HOLDING)) %>%
dplyr::group_by(FACTSET_FUND_ID, TICKER_EXCHANGE, Q_Ends) %>%
dplyr::summarise(HOLDING_tot = sum(HOLDING, na.rm = TRUE),
Symbol = dplyr::first(Symbol),
CAP_GROUP = as.factor(dplyr::first(CAP_GROUP)),
SECTOR_CODE = as.factor(dplyr::first(SECTOR_CODE))
) %>% dplyr::ungroup() %>%
# Enriching the ownership data with the fundamental data of the company
dplyr::left_join(Fundamental_data, by = c("Symbol", "Q_Ends")) %>%
dplyr::group_by(Symbol) %>% dplyr::arrange(Q_Ends) %>%
dplyr::mutate(HOLDING_chng = HOLDING_tot - lag(HOLDING_tot),
Buy_Sell = as.factor(ifelse(HOLDING_chng < 0, "Sell", "Buy"))) %>%
dplyr::ungroup() %>% dplyr::arrange(Symbol, Q_Ends)
# Specifying the regression variables
data.set <- na.omit(data.set) %>%
# Eliminating context (uneccessary) variable
dplyr::select(-FACTSET_FUND_ID, -TICKER_EXCHANGE, -Q_Ends, -HOLDING_tot, -Symbol)
Y_Var <- "Buy_Sell"
X_Var <-  setdiff(names(data.set), Y_Var)
# Splitting the data_set into training and testing set based on proportion variable
n_samples <- floor(NROW(data.set) * FRACTION_TRAINING)
sample_ids <- sample.int(n = NROW(data.set), size = n_samples, replace = FALSE)
Training_data <- data.set[sample_ids , c(Y_Var, X_Var)]
Test_data     <- data.set[-sample_ids, c(Y_Var, X_Var)]
X <- model.matrix( ~ .-1, data = Training_data[, X_Var])
Y <- as.numeric(Training_data[[Y_Var]])
# Cross validation for hyper-parameter estimation
N_folds <- 10
fold_id <- sample(1:N_folds,size=length(Y),replace=TRUE)
glmnet_lasso <- glmnet::cv.glmnet(X,Y, intercept=FALSE, foldid=fold_id, alpha=1, family = "binomial", type.measure="class") ## lasso regression - Sparse coeff
# Determine the optimal probability thereshold value to determine the class (buy vs sell)
# https://hopstat.wordpress.com/2014/12/19/a-small-introduction-to-the-rocr-package/
# Logit model
pred_logit <- prediction(predictions = predict(glmnet_lasso,
newx = model.matrix( ~ .-1, data = Training_data[, X_Var]),
# as.matrix(Training_data[,which(names(Training_data_classification) != "Buy_Sell")]),
s = "lambda.min", type = "response"),
labels = Training_data[, Y_Var])
# Equal cost for FP and FN
cost.perf  <- performance(pred_logit, "cost", cost.fp = 1, cost.fn = 1)
opt_threshold <- pred_logit@cutoffs[[1]][which.min(cost.perf@y.values[[1]])]
# Determining Predictive accuracy -----
browser()
X_test <- model.matrix( ~ .-1, data = Test_data[, X_Var])
Test_data$Y_prob <- predict(glmnet_lasso, s='lambda.min', newx=X_test, type="response")  %>% as.vector()
Test_data$pred_glmnet_lasso_Buy_Sell <- ifelse(Test_data$Y_prob > opt_threshold, "Sell", "Buy")
# Creating Results data.frame
Results <- Test_data %>% dplyr::mutate(
# Predicted Buy/Sell given Buy/Sell
pred_Buy_given_Buy_Lasso    = ifelse(pred_glmnet_lasso_Buy_Sell == "Buy"  & Buy_Sell == "Buy" , TRUE, FALSE),
pred_Buy_given_Sell_Lasso   = ifelse(pred_glmnet_lasso_Buy_Sell == "Buy"  & Buy_Sell == "Sell", TRUE, FALSE),
pred_Sell_given_Buy_Lasso   = ifelse(pred_glmnet_lasso_Buy_Sell == "Sell" & Buy_Sell == "Buy" , TRUE, FALSE),
pred_Sell_given_Sell_Lasso  = ifelse(pred_glmnet_lasso_Buy_Sell == "Sell" & Buy_Sell == "Sell", TRUE, FALSE),
## Buy/Sell given Predicted Buy/Sell
Buy_given_Pred_Buy_Lasso   = ifelse(Buy_Sell == "Buy"  & pred_glmnet_lasso_Buy_Sell == "Buy" , TRUE, FALSE),
Buy_given_Pred_Sell_Lasso  = ifelse(Buy_Sell == "Buy"  & pred_glmnet_lasso_Buy_Sell == "Sell", TRUE, FALSE),
Sell_given_Pred_Buy_Lasso  = ifelse(Buy_Sell == "Sell" & pred_glmnet_lasso_Buy_Sell == "Buy" , TRUE, FALSE),
Sell_given_Pred_Sell_Lasso = ifelse(Buy_Sell == "Sell" & pred_glmnet_lasso_Buy_Sell == "Sell", TRUE, FALSE),
# Accuracy
Correct_pred_GLMnet_Lasso   = ifelse(pred_glmnet_lasso_Buy_Sell == Buy_Sell, TRUE, FALSE)
) %>% dplyr::summarise(
# TestData statistics
Count = as.integer(n()),
Count_Buy  = as.integer(sum(Buy_Sell == "Buy")),
Count_Sell = as.integer(sum(Buy_Sell == "Sell")),
Percent_buy = paste(round(100 * Count_Buy/Count, digits = 2), "%"),
Percent_sell =  paste(round(100 * Count_Sell/Count,digits = 2), "%"),
# GLMnet Lasso
<<<<<<< HEAD
# ============
#
# Predicted Buy/Sell given Buy/Sell
Prob_pred_Buy_given_Buy_Lasso   = paste(round(100 * sum(pred_Buy_given_Buy_Lasso == TRUE)  /Count_Buy,digits = 2),"%"),
Prob_pred_Buy_given_Sell_Lasso  = paste(round(100 * sum(pred_Buy_given_Sell_Lasso == TRUE) /Count_Sell,digits = 2),"%"),
Prob_pred_Sell_given_Buy_Lasso  = paste(round(100 * sum(pred_Sell_given_Buy_Lasso == TRUE) /Count_Buy,digits = 2),"%"),
Prob_pred_Sell_given_Sell_Lasso = paste(round(100 * sum(pred_Sell_given_Sell_Lasso == TRUE)/Count_Sell,digits = 2),"%"),
# Buy/Sell given Predicted Buy/Sell
Prob_Buy_given_pred_Buy_Lasso   = paste(round(100 * sum(Buy_given_Pred_Buy_Lasso == TRUE)  /sum(pred_glmnet_lasso_Buy_Sell == "Buy" ),digits = 2),"%"),
Prob_Buy_given_pred_Sell_Lasso  = paste(round(100 * sum(Buy_given_Pred_Sell_Lasso == TRUE) /sum(pred_glmnet_lasso_Buy_Sell == "Sell"),digits = 2),"%"),
Prob_Sell_given_pred_Buy_Lasso  = paste(round(100 * sum(Sell_given_Pred_Buy_Lasso == TRUE) /sum(pred_glmnet_lasso_Buy_Sell == "Buy" ),digits = 2),"%"),
Prob_Sell_given_pred_Sell_Lasso = paste(round(100 * sum(Sell_given_Pred_Sell_Lasso == TRUE)/sum(pred_glmnet_lasso_Buy_Sell == "Sell"),digits = 2),"%"),
# Accuracy
Pred_Accuracy_GLMnet_Lasso      = paste(round(100 * sum(Correct_pred_GLMnet_Lasso == TRUE) /Count,digits = 2),"%")) %>% as.vector()
Results <- cbind(fund = f, Results)
# Saving model to disk for future use
outCon <- file(paste0(save.model.path,f,".txt"), "w")
model.char <- rawToChar(serialize(glmnet_lasso, NULL, ascii=T))
cat(model.char, file=outCon); close(outCon)
Results_final[[counter]] <- Results
=======
Prob_Buy_given_Buy_Lasso   = paste(round(100 * sum(pred_Buy_given_Buy_Lasso == TRUE)  /Count_Buy,digits = 2),"%"),
Prob_Buy_given_Sell_Lasso  = paste(round(100 * sum(pred_Buy_given_Sell_Lasso == TRUE) /Count_Sell,digits = 2),"%"),
Prob_Sell_given_Buy_Lasso  = paste(round(100 * sum(pred_Sell_given_Buy_Lasso == TRUE) /Count_Buy,digits = 2),"%"),
Prob_Sell_given_Sell_Lasso = paste(round(100 * sum(pred_Sell_given_Sell_Lasso == TRUE)/Count_Sell,digits = 2),"%"),
accuracy_GLMnet_Lasso      = paste(round(100 * sum(Correct_pred_GLMnet_Lasso == TRUE) /Count,digits = 2),"%"),
#GLMnet Ridge
Prob_Buy_given_Buy_Ridge   = paste(round(100 * sum(pred_Buy_given_Buy_Ridge == TRUE)  /Count_Buy,digits = 2),"%"),
Prob_Buy_given_Sell_Ridge  = paste(round(100 * sum(pred_Buy_given_Sell_Ridge == TRUE) /Count_Sell,digits = 2),"%"),
Prob_Sell_given_Buy_Ridge  = paste(round(100 * sum(pred_Sell_given_Buy_Ridge == TRUE) /Count_Buy,digits = 2),"%"),
Prob_Sell_given_Sell_Ridge = paste(round(100 * sum(pred_Sell_given_Sell_Ridge == TRUE)/Count_Sell,digits = 2),"%"),
accuracy_GLMnet_Ridge      = paste(round(100 * sum(Correct_pred_GLMnet_Ridge == TRUE)/Count, digits = 2), "%")) %>%
t()
probability_threshold   = paste0("Threshold: ",round(100 * threshold, digits = 2), "%")
colnames(Results_Summary) <- probability_threshold
res <- list(Summary = Results_Summary, TestResults = Results_focus, Thresh = threshold)
return(res)
}
Results_Summary_1 <- ModelPreictionResults(threshold = opt_t )$Summary # Result summary associated with opt_t
Results_Summary_2 <- ModelPreictionResults(threshold = opt_t2)$Summary # Result summary associated with opt_t2
Results_Summary_3 <- ModelPreictionResults(threshold = opt_t3)$Summary # Result summary associated with opt_t3
Results_Summary_4 <- ModelPreictionResults(threshold = opt_t4)$Summary # Result summary associated with opt_t4
Results_Summary_5 <- ModelPreictionResults(threshold = opt_t5)$Summary # Result summary associated with opt_t5
Results_Summary_all <- cbind(Results_Summary_1, Results_Summary_2, Results_Summary_3, Results_Summary_4, Results_Summary_5)
View(Results_Summary_all)
(opt_t, opt_t2, opt_t3, opt_t4, opt_t5)
(opt_t, opt_t2, opt_t3, opt_t4, opt_t5)
c(opt_t, opt_t2, opt_t3, opt_t4, opt_t5)
rank(c(opt_t, opt_t2, opt_t3, opt_t4, opt_t5))
Results_Summary_all <- Results_Summary_all[, rank(c(opt_t, opt_t2, opt_t3, opt_t4, opt_t5))]
View(Results_Summary_all)
Results_Summary_all <- cbind(Results_Summary_5, Results_Summary_4, Results_Summary_2, Results_Summary_1, Results_Summary_3)
View(Results_Summary_all)
opt_t_models
write.csv(Results_Summary_all, "./output_files/Results_Summary.csv", row.names = TRUE, col.names = TRUE)
=======
SharkPositions_good <- data.set <- dplyr::semi_join(SharkPositions, good_symbols_list, by = "Symbol")
data_path <- "~/Data/Fundamentals_9_17_2016/fundamentals_9_17_2016"
files <- dir(path = data_path, pattern = "_Request")
data.set <- dbReadTable(con, "SharkPositions_good") %>% dplyr::mutate(Date = as.Date(Date))
tbls_list <- dbListTables(con)
counter <- 0
pryr::mem_used()
for(t in tbls_list[1:10]) {
# Verbose msg
counter <<- counter + 1
message(paste0("Processing table number: ", counter, ". TableName/Fundamental data: ", t, ". Memory used: ", pryr::mem_used()))
# Looping through all the tables in the db excluding the sharkpositions table
if (t %in% c("sharkpositions", "sharkpositions_good")) next
data.X <- dbReadTable(con, t) %>% dplyr::mutate(Date = as.Date(Date)) %>%
dplyr::rowwise() %>% dplyr::mutate(Next_Pos_date = suppressWarnings(Positions_dates[min(which(Positions_dates > Date))]))
# Renaming the variable before adding them to the data_set
names(data.X)[which(names(data.X) == "Date")] <- paste0("Date_", t)
if(NCOL(data.X) > 3) names(data.X)[which(names(data.X) == "Value")] <- t
# Constructing the dataset
data.set <<- dplyr::left_join(data.set, data.X, by = c("Symbol", "Date" = "Next_Pos_date"))
saveRDS(data.set, file = "DataSet.rds")
rm(data.X)
gc()
}
Positions_dates <- sort(unique(SharkPositions$Date))
data.set <- dbReadTable(con, "SharkPositions_good") %>% dplyr::mutate(Date = as.Date(Date))
tbls_list <- dbListTables(con)
counter <- 0
pryr::mem_used()
for(t in tbls_list[1:10]) {
# Verbose msg
counter <<- counter + 1
message(paste0("Processing table number: ", counter, ". TableName/Fundamental data: ", t, ". Memory used: ", pryr::mem_used()))
# Looping through all the tables in the db excluding the sharkpositions table
if (t %in% c("sharkpositions", "sharkpositions_good")) next
data.X <- dbReadTable(con, t) %>% dplyr::mutate(Date = as.Date(Date)) %>%
dplyr::rowwise() %>% dplyr::mutate(Next_Pos_date = suppressWarnings(Positions_dates[min(which(Positions_dates > Date))]))
# Renaming the variable before adding them to the data_set
names(data.X)[which(names(data.X) == "Date")] <- paste0("Date_", t)
if(NCOL(data.X) > 3) names(data.X)[which(names(data.X) == "Value")] <- t
# Constructing the dataset
data.set <<- dplyr::left_join(data.set, data.X, by = c("Symbol", "Date" = "Next_Pos_date"))
saveRDS(data.set, file = "DataSet.rds")
rm(data.X)
gc()
}
gc()
pryr::mem_used()
save.image("WorkSpace_1tmp.RData")
pryr::mem_used()
for(i in 1:10){
gc()
sleep(0.5)
}
for(i in 1:10){
gc()
Sys.sleep(0.5)
}
pryr::mem_used()
gc()
pryr::mem_used()
Positions_dates <- sort(unique(SharkPositions$Date))
good_symbols_list <- dplyr::filter(transaction_per_symbol_per_year, Count <= 4) %>% dplyr::distinct()
library(RMySQL)
con <- dbConnect(RMySQL::MySQL(), default.file = .rmysql.settingsfile, group = "local_intel")
SharkPositions_good <- data.set <- dplyr::semi_join(SharkPositions, good_symbols_list, by = "Symbol")
data_path <- "~/Data/Fundamentals_9_17_2016/fundamentals_9_17_2016"
saveRDS(data.set, file = "DataSet.rds")
tbls_list <- dbListTables(con)
counter <- 0
pryr::mem_used()
for(t in tbls_list[1:8]) {
# Verbose msg
counter <<- counter + 1
data.set <<- readRDS(DataSet.rds)
message(paste0("Processing table number: ", counter, ". TableName/Fundamental data: ", t, ". Memory used: ", pryr::mem_used()))
# Looping through all the tables in the db excluding the sharkpositions table
if (t %in% c("sharkpositions", "sharkpositions_good")) next
data.X <- dbReadTable(con, t) %>% dplyr::mutate(Date = as.Date(Date)) %>%
dplyr::rowwise() %>% dplyr::mutate(Next_Pos_date = suppressWarnings(Positions_dates[min(which(Positions_dates > Date))]))
# Renaming the variable before adding them to the data_set
names(data.X)[which(names(data.X) == "Date")] <- paste0("Date_", t)
if(NCOL(data.X) > 3) names(data.X)[which(names(data.X) == "Value")] <- t
# Constructing the dataset
data.set <<- dplyr::left_join(data.set, data.X, by = c("Symbol", "Date" = "Next_Pos_date"))
saveRDS(data.set, file = "DataSet.rds")
rm(data.X)
rm(data.set)
gc()
}
tbls_list <- dbListTables(con)
counter <- 0
pryr::mem_used()
for(t in tbls_list[1:8]) {
# Verbose msg
counter <<- counter + 1
data.set <<- readRDS("DataSet.rds")
message(paste0("Processing table number: ", counter, ". TableName/Fundamental data: ", t, ". Memory used: ", pryr::mem_used()))
# Looping through all the tables in the db excluding the sharkpositions table
if (t %in% c("sharkpositions", "sharkpositions_good")) next
data.X <- dbReadTable(con, t) %>% dplyr::mutate(Date = as.Date(Date)) %>%
dplyr::rowwise() %>% dplyr::mutate(Next_Pos_date = suppressWarnings(Positions_dates[min(which(Positions_dates > Date))]))
# Renaming the variable before adding them to the data_set
names(data.X)[which(names(data.X) == "Date")] <- paste0("Date_", t)
if(NCOL(data.X) > 3) names(data.X)[which(names(data.X) == "Value")] <- t
# Constructing the dataset
data.set <<- dplyr::left_join(data.set, data.X, by = c("Symbol", "Date" = "Next_Pos_date"))
saveRDS(data.set, file = "DataSet.rds")
rm(data.X)
rm(data.set)
gc()
}
pryr::mem_used()
counter
for(t in tbls_list[9:17]) {
# Verbose msg
counter <<- counter + 1
data.set <<- readRDS("DataSet.rds")
message(paste0("Processing table number: ", counter, ". TableName/Fundamental data: ", t, ". Memory used: ", pryr::mem_used()))
>>>>>>> 0c484179b03a9984cb4a73d42a5e6d8bb53378ce
# Looping through all the tables in the db excluding the sharkpositions table
if (t %in% c("sharkpositions", "sharkpositions_good")) next
data.X <- dbReadTable(con, t) %>% dplyr::mutate(Date = as.Date(Date)) %>%
dplyr::rowwise() %>% dplyr::mutate(Next_Pos_date = suppressWarnings(Positions_dates[min(which(Positions_dates > Date))]))
# Renaming the variable before adding them to the data_set
names(data.X)[which(names(data.X) == "Date")] <- paste0("Date_", t)
if(NCOL(data.X) > 3) names(data.X)[which(names(data.X) == "Value")] <- t
# Constructing the dataset
data.set <<- dplyr::left_join(data.set, data.X, by = c("Symbol", "Date" = "Next_Pos_date"))
saveRDS(data.set, file = "DataSet.rds")
rm(data.X)
rm(data.set)
gc()
}
library(RMySQL)
con <- dbConnect(RMySQL::MySQL(), default.file = .rmysql.settingsfile, group = "local_intel")
dbListTables(con)
dbWriteTable(con, "SharkPositions", SharkPositions)
Positions_dates <- sort(unique(SharkPositions$Date))
good_symbols_list <- dplyr::filter(transaction_per_symbol_per_year, Count <= 4) %>% dplyr::distinct()
SharkPositions_good <- data.set <- dplyr::semi_join(SharkPositions, good_symbols_list, by = "Symbol")
data_path <- "~/Data/Fundamentals_9_17_2016/fundamentals_9_17_2016"
files <- dir(path = data_path, pattern = "_Request")
pryr::mem_used()
counter <- 0
tbls_list <- dbListTables(con)
saveRDS(data.set, file = "DataSet.rds")
for(t in tbls_list[1:9]) {
# Verbose msg
counter <<- counter + 1
data.set <<- readRDS("DataSet.rds")
message(paste0("Processing table number: ", counter, ". TableName/Fundamental data: ", t, ". Memory used: ", pryr::mem_used()))
# Looping through all the tables in the db excluding the sharkpositions table
if (t %in% c("sharkpositions", "sharkpositions_good")) next
data.X <- dbReadTable(con, t) %>% dplyr::mutate(Date = as.Date(Date)) %>%
dplyr::rowwise() %>% dplyr::mutate(Next_Pos_date = suppressWarnings(Positions_dates[min(which(Positions_dates > Date))]))
# Renaming the variable before adding them to the data_set
names(data.X)[which(names(data.X) == "Date")] <- paste0("Date_", t)
if(NCOL(data.X) > 3) names(data.X)[which(names(data.X) == "Value")] <- t
# Constructing the dataset
data.set <<- dplyr::left_join(data.set, data.X, by = c("Symbol", "Date" = "Next_Pos_date"))
saveRDS(data.set, file = "DataSet.rds")
rm(data.X)
rm(data.set)
gc()
}
Positions_dates <- sort(unique(SharkPositions$Date))
good_symbols_list <- dplyr::filter(transaction_per_symbol_per_year, Count <= 4) %>% dplyr::distinct()
library(RMySQL)
con <- dbConnect(RMySQL::MySQL(), default.file = .rmysql.settingsfile, group = "local_intel")
SharkPositions_good <- data.set <- dplyr::semi_join(SharkPositions, good_symbols_list, by = "Symbol")
tbls_list <- dbListTables(con)
for(t in tbls_list[10:19]) {
# Verbose msg
counter <<- counter + 1
data.set <<- readRDS("DataSet.rds")
message(paste0("Processing table number: ", counter, ". TableName/Fundamental data: ", t, ". Memory used: ", pryr::mem_used()))
# Looping through all the tables in the db excluding the sharkpositions table
if (t %in% c("sharkpositions", "sharkpositions_good")) next
data.X <- dbReadTable(con, t) %>% dplyr::mutate(Date = as.Date(Date)) %>%
dplyr::rowwise() %>% dplyr::mutate(Next_Pos_date = suppressWarnings(Positions_dates[min(which(Positions_dates > Date))]))
# Renaming the variable before adding them to the data_set
names(data.X)[which(names(data.X) == "Date")] <- paste0("Date_", t)
if(NCOL(data.X) > 3) names(data.X)[which(names(data.X) == "Value")] <- t
# Constructing the dataset
data.set <<- dplyr::left_join(data.set, data.X, by = c("Symbol", "Date" = "Next_Pos_date"))
saveRDS(data.set, file = "DataSet.rds")
rm(data.X)
rm(data.set)
gc()
}
counter <- 9
pryr::mem_used()
for(t in tbls_list[10:19]) {
# Verbose msg
counter <<- counter + 1
data.set <<- readRDS("DataSet.rds")
message(paste0("Processing table number: ", counter, ". TableName/Fundamental data: ", t, ". Memory used: ", pryr::mem_used()))
# Looping through all the tables in the db excluding the sharkpositions table
if (t %in% c("sharkpositions", "sharkpositions_good")) next
data.X <- dbReadTable(con, t) %>% dplyr::mutate(Date = as.Date(Date)) %>%
dplyr::rowwise() %>% dplyr::mutate(Next_Pos_date = suppressWarnings(Positions_dates[min(which(Positions_dates > Date))]))
# Renaming the variable before adding them to the data_set
names(data.X)[which(names(data.X) == "Date")] <- paste0("Date_", t)
if(NCOL(data.X) > 3) names(data.X)[which(names(data.X) == "Value")] <- t
# Constructing the dataset
data.set <<- dplyr::left_join(data.set, data.X, by = c("Symbol", "Date" = "Next_Pos_date"))
saveRDS(data.set, file = "DataSet.rds")
rm(data.X)
rm(data.set)
gc()
}
pryr::mem_used()
data.set <<- readRDS("DataSet.rds")
pryr::mem_used()
View(data.set)
NROW(SharkPositions)
NROW(data.set)
library(RMySQL)
con <- dbConnect(RMySQL::MySQL(),  default.file = "~/.my.cnf", group = "local_intel")
dbListTables(con)
dbListTables(con)
data.set <- dbReadTable(con, "SharkPositions_good") %>% dplyr::mutate(Date = as.Date(Date))
# saveRDS(data.set, file = "DataSet.rds")
tbls_list <- dbListTables(con)
counter <- 0
pryr::mem_used()
for(t in tbls_list) {
# Verbose msg
counter <<- counter + 1
#data.set <<- readRDS("DataSet.rds")
message(paste0("Processing table number: ", counter, ". TableName/Fundamental data: ", t, ". Memory used: ", pryr::mem_used()))
# Looping through all the tables in the db excluding the sharkpositions table
if (t %in% c("sharkpositions", "sharkpositions_good", "SharkPositions" , "SharkPositions_good" , "data_set")) next
data.X <- dbReadTable(con, t) %>% dplyr::mutate(Date = as.Date(Date)) %>%
dplyr::rowwise() %>%
dplyr::mutate(Next_Pos_date = suppressWarnings(Positions_dates[min(which(Positions_dates > Date))])) %>%
dplyr::ungroup() %>%
# Keeping only 1 data point per symbol per Position Date
dplyr::arrange(Symbol, desc(Date)) %>%
dplyr::distinct(Symbol, Next_Pos_date, .keep_all = TRUE)
# Renaming the variable before adding them to the data_set
names(data.X)[which(names(data.X) == "Date")] <- paste0("Date_", t)
if(NCOL(data.X) > 3) names(data.X)[which(names(data.X) == "Value")] <- t
# Constructing the dataset
data.set <<- dplyr::left_join(data.set, data.X, by = c("Symbol", "Date" = "Next_Pos_date"))
#saveRDS(data.set, file = "DataSet.rds")
names(data.set)
rm(data.X)
gc()
}
data.set <- data.set %>% dplyr::arrange(Symbol, Date)
Positions_dates <- sort(unique(SharkPositions$Date))
data.set <- dbReadTable(con, "SharkPositions_good") %>% dplyr::mutate(Date = as.Date(Date))
# saveRDS(data.set, file = "DataSet.rds")
tbls_list <- dbListTables(con)
counter <- 0
pryr::mem_used()
for(t in tbls_list) {
# Verbose msg
counter <<- counter + 1
#data.set <<- readRDS("DataSet.rds")
message(paste0("Processing table number: ", counter, ". TableName/Fundamental data: ", t, ". Memory used: ", pryr::mem_used()))
# Looping through all the tables in the db excluding the sharkpositions table
if (t %in% c("sharkpositions", "sharkpositions_good", "SharkPositions" , "SharkPositions_good" , "data_set")) next
data.X <- dbReadTable(con, t) %>% dplyr::mutate(Date = as.Date(Date)) %>%
dplyr::rowwise() %>%
dplyr::mutate(Next_Pos_date = suppressWarnings(Positions_dates[min(which(Positions_dates > Date))])) %>%
dplyr::ungroup() %>%
# Keeping only 1 data point per symbol per Position Date
dplyr::arrange(Symbol, desc(Date)) %>%
dplyr::distinct(Symbol, Next_Pos_date, .keep_all = TRUE)
# Renaming the variable before adding them to the data_set
names(data.X)[which(names(data.X) == "Date")] <- paste0("Date_", t)
if(NCOL(data.X) > 3) names(data.X)[which(names(data.X) == "Value")] <- t
# Constructing the dataset
data.set <<- dplyr::left_join(data.set, data.X, by = c("Symbol", "Date" = "Next_Pos_date"))
#saveRDS(data.set, file = "DataSet.rds")
names(data.set)
rm(data.X)
gc()
>>>>>>> 24a3fe80a629ed7915a6998dfa68630637e404de
}
counter <- 0  # about 49 tables to process
FRACTION_TRAINING <- 0.75
save.model.path <- "./ModelResults/"
Results_final <- list()
for(f in funds_ids$FACTSET_FUND_ID) {
counter <<- counter + 1
message(paste0("Processing fund:", f ,". Memory used: ", pryr::mem_used()))
qry <- paste0("SELECT * FROM fund_us_holdings_hist_w_symbols_and_sic where FACTSET_FUND_ID = '",f , "'")
data.set <- dbGetQuery(con, qry)
data.set <- data.set %>%
dplyr::mutate(Q_Ends = as.Date(timeDate::timeLastDayInQuarter(REPORT_DATE, format = "%Y-%m-%d", zone = "", FinCenter = "")),
HOLDING = as.numeric(HOLDING)) %>%
dplyr::group_by(FACTSET_FUND_ID, TICKER_EXCHANGE, Q_Ends) %>%
dplyr::summarise(HOLDING_tot = sum(HOLDING, na.rm = TRUE),
Symbol = dplyr::first(Symbol),
CAP_GROUP = as.factor(dplyr::first(CAP_GROUP)),
SECTOR_CODE = as.factor(dplyr::first(SECTOR_CODE))
) %>% dplyr::ungroup() %>%
# Enriching the ownership data with the fundamental data of the company
dplyr::left_join(Fundamental_data, by = c("Symbol", "Q_Ends")) %>%
dplyr::group_by(Symbol) %>% dplyr::arrange(Q_Ends) %>%
dplyr::mutate(HOLDING_chng = HOLDING_tot - lag(HOLDING_tot),
Buy_Sell = as.factor(ifelse(HOLDING_chng < 0, "Sell", "Buy"))) %>%
dplyr::ungroup() %>% dplyr::arrange(Symbol, Q_Ends)
# Specifying the regression variables
data.set <- na.omit(data.set) %>%
# Eliminating context (uneccessary) variable
dplyr::select(-FACTSET_FUND_ID, -TICKER_EXCHANGE, -Q_Ends, -HOLDING_tot, -Symbol)
Y_Var <- "Buy_Sell"
X_Var <-  setdiff(names(data.set), Y_Var)
# Splitting the data_set into training and testing set based on proportion variable
n_samples <- floor(NROW(data.set) * FRACTION_TRAINING)
sample_ids <- sample.int(n = NROW(data.set), size = n_samples, replace = FALSE)
Training_data <- data.set[sample_ids , c(Y_Var, X_Var)]
Test_data     <- data.set[-sample_ids, c(Y_Var, X_Var)]
X <- model.matrix( ~ .-1, data = Training_data[, X_Var])
Y <- as.numeric(Training_data[[Y_Var]])
# Cross validation for hyper-parameter estimation
N_folds <- 10
fold_id <- sample(1:N_folds,size=length(Y),replace=TRUE)
glmnet_lasso <- glmnet::cv.glmnet(X,Y, intercept=FALSE, foldid=fold_id, alpha=1, family = "binomial", type.measure="class") ## lasso regression - Sparse coeff
# Determine the optimal probability thereshold value to determine the class (buy vs sell)
# https://hopstat.wordpress.com/2014/12/19/a-small-introduction-to-the-rocr-package/
# Logit model
pred_logit <- prediction(predictions = predict(glmnet_lasso,
newx = model.matrix( ~ .-1, data = Training_data[, X_Var]),
# as.matrix(Training_data[,which(names(Training_data_classification) != "Buy_Sell")]),
s = "lambda.min", type = "response"),
labels = Training_data[, Y_Var])
# Equal cost for FP and FN
cost.perf  <- performance(pred_logit, "cost", cost.fp = 1, cost.fn = 1)
opt_threshold <- pred_logit@cutoffs[[1]][which.min(cost.perf@y.values[[1]])]
# Determining Predictive accuracy -----
browser()
X_test <- model.matrix( ~ .-1, data = Test_data[, X_Var])
Test_data$Y_prob <- predict(glmnet_lasso, s='lambda.min', newx=X_test, type="response")  %>% as.vector()
Test_data$pred_glmnet_lasso_Buy_Sell <- ifelse(Test_data$Y_prob > opt_threshold, "Sell", "Buy")
# Creating Results data.frame
Results <- Test_data %>% dplyr::mutate(
# Predicted Buy/Sell given Buy/Sell
pred_Buy_given_Buy_Lasso    = ifelse(pred_glmnet_lasso_Buy_Sell == "Buy"  & Buy_Sell == "Buy" , TRUE, FALSE),
pred_Buy_given_Sell_Lasso   = ifelse(pred_glmnet_lasso_Buy_Sell == "Buy"  & Buy_Sell == "Sell", TRUE, FALSE),
pred_Sell_given_Buy_Lasso   = ifelse(pred_glmnet_lasso_Buy_Sell == "Sell" & Buy_Sell == "Buy" , TRUE, FALSE),
pred_Sell_given_Sell_Lasso  = ifelse(pred_glmnet_lasso_Buy_Sell == "Sell" & Buy_Sell == "Sell", TRUE, FALSE),
## Buy/Sell given Predicted Buy/Sell
Buy_given_Pred_Buy_Lasso   = ifelse(Buy_Sell == "Buy"  & pred_glmnet_lasso_Buy_Sell == "Buy" , TRUE, FALSE),
Buy_given_Pred_Sell_Lasso  = ifelse(Buy_Sell == "Buy"  & pred_glmnet_lasso_Buy_Sell == "Sell", TRUE, FALSE),
Sell_given_Pred_Buy_Lasso  = ifelse(Buy_Sell == "Sell" & pred_glmnet_lasso_Buy_Sell == "Buy" , TRUE, FALSE),
Sell_given_Pred_Sell_Lasso = ifelse(Buy_Sell == "Sell" & pred_glmnet_lasso_Buy_Sell == "Sell", TRUE, FALSE),
# Accuracy
Correct_pred_GLMnet_Lasso   = ifelse(pred_glmnet_lasso_Buy_Sell == Buy_Sell, TRUE, FALSE)
) %>% dplyr::summarise(
# TestData statistics
Count = as.integer(n()),
Count_Buy  = as.integer(sum(Buy_Sell == "Buy")),
Count_Sell = as.integer(sum(Buy_Sell == "Sell")),
Percent_buy = paste(round(100 * Count_Buy/Count, digits = 2), "%"),
Percent_sell =  paste(round(100 * Count_Sell/Count,digits = 2), "%"),
# GLMnet Lasso
# ============
#
# Predicted Buy/Sell given Buy/Sell
Prob_pred_Buy_given_Buy_Lasso   = paste(round(100 * sum(pred_Buy_given_Buy_Lasso == TRUE)  /Count_Buy,digits = 2),"%"),
Prob_pred_Buy_given_Sell_Lasso  = paste(round(100 * sum(pred_Buy_given_Sell_Lasso == TRUE) /Count_Sell,digits = 2),"%"),
Prob_pred_Sell_given_Buy_Lasso  = paste(round(100 * sum(pred_Sell_given_Buy_Lasso == TRUE) /Count_Buy,digits = 2),"%"),
Prob_pred_Sell_given_Sell_Lasso = paste(round(100 * sum(pred_Sell_given_Sell_Lasso == TRUE)/Count_Sell,digits = 2),"%"),
# Buy/Sell given Predicted Buy/Sell
Prob_Buy_given_pred_Buy_Lasso   = paste(round(100 * sum(Buy_given_Pred_Buy_Lasso == TRUE)  /sum(pred_glmnet_lasso_Buy_Sell == "Buy" ),digits = 2),"%"),
Prob_Buy_given_pred_Sell_Lasso  = paste(round(100 * sum(Buy_given_Pred_Sell_Lasso == TRUE) /sum(pred_glmnet_lasso_Buy_Sell == "Sell"),digits = 2),"%"),
Prob_Sell_given_pred_Buy_Lasso  = paste(round(100 * sum(Sell_given_Pred_Buy_Lasso == TRUE) /sum(pred_glmnet_lasso_Buy_Sell == "Buy" ),digits = 2),"%"),
Prob_Sell_given_pred_Sell_Lasso = paste(round(100 * sum(Sell_given_Pred_Sell_Lasso == TRUE)/sum(pred_glmnet_lasso_Buy_Sell == "Sell"),digits = 2),"%"),
# Accuracy
Pred_Accuracy_GLMnet_Lasso      = paste(round(100 * sum(Correct_pred_GLMnet_Lasso == TRUE) /Count,digits = 2),"%")) %>% as.vector()
Results <- cbind(fund = f, Results)
# Saving model to disk for future use
outCon <- file(paste0(save.model.path,f,".txt"), "w")
model.char <- rawToChar(serialize(glmnet_lasso, NULL, ascii=T))
cat(model.char, file=outCon); close(outCon)
Results_final[[counter]] <- Results
}
<<<<<<< HEAD
Results_final2 <- dplyr::bind_rows(Results_final)
View(Results_final2)
=======
scanned_data <- data.set3[, c(Y_var, X_var)] %>% # partition() %>%
dplyr::group_by(Year) %>% dplyr::do(res = my_func(.))
<<<<<<< HEAD
RANDOM_TRAINING <- FALSE
FRACTION_TRAINING <- 0.75
if(RANDOM_TRAINING == TRUE) {
n_samples <- floor(NROW(data.set3) * FRACTION_TRAINING)
sample_ids <- sample.int(n = NROW(data.set3), size = n_samples, replace = FALSE)
Training_data_regression <- data.set3[sample_ids , c(Y_var, X_var)]
Test_data_regression     <- data.set3[-sample_ids, c(Y_var, X_var)]
} else {
# Splitting training/Testing
Years_dataset <- as.numeric(sort(unique(data.set3$Year)))
Test_years <- c(2015)
Training_years <- setdiff(Years_dataset, Test_years)
Training_data_regression <- dplyr::filter(data.set3, Year %in% Training_years) %>%
dplyr::select_(.dots = c(Y_var, X_var))
Test_data_regression <- dplyr::filter(data.set3, Year %in% Test_years) %>%
dplyr::select_(.dots = c(Y_var, X_var))
}
# Classification data sets -----
Training_data_classification <- Training_data_regression
Training_data_classification$Buy_Sell <- as.factor(ifelse(Training_data_regression[,Y_var] > 0, "Buy", "Sell"))
Training_data_classification <- Training_data_classification[, -which(names(Training_data_classification) == Y_var)]
Test_data_classification <- Test_data_regression
Test_data_classification$Buy_Sell <- as.factor(ifelse(Test_data_regression[,Y_var] > 0, "Buy", "Sell"))
Test_data_classification <- Test_data_classification[, -which(names(Test_data_classification) == Y_var)]
library(FSelector)
install.packages("FSelector")
features_information.gain_classification <- information.gain(formula = Buy_Sell ~ ., data = Training_data_classification)
library(FSelector)
library(FSelector)
library(FSelector)
library(rJava)
Sys.setenv(JAVA_HOME='C:\\Program Files\\Java\\jre7') # for 64-bit version
library(rJava)
Sys.setenv(JAVA_HOME='C:\\Program Files (x86)\\Java\\jre1.8.0_111') # for 64-bit version
library(rJava)
library(FSelector)
features_information.gain_classification <- information.gain(formula = Buy_Sell ~ ., data = Training_data_classification)
features_gain.ratio_classification <- gain.ratio(formula = Buy_Sell ~ ., data = Training_data_classification)
features_randomForest <- random.forest.importance(formula = Buy_Sell ~ ., data = Training_data_classification, importance.type = 1)
sapply(Training_data_classification, function(x) class(x))
context_var <- c("Symbol", "Year",  "Date",
"HasOptions", "SharkGrouping", "NumberHolders", "SharesOutstanding", "FSPermSecId")
Y_var_potential <- grep(pattern = "Position", x = names(data.set3), value = TRUE)
Y_var <- "Position_change"
X_var <-  setdiff(names(data.set3),
union(Y_var_potential, context_var))
# Identification of Training & Testing data set ------
# Random Sample vs Specific years for training set
RANDOM_TRAINING <- FALSE
FRACTION_TRAINING <- 0.75
if(RANDOM_TRAINING == TRUE) {
n_samples <- floor(NROW(data.set3) * FRACTION_TRAINING)
sample_ids <- sample.int(n = NROW(data.set3), size = n_samples, replace = FALSE)
Training_data_regression <- data.set3[sample_ids , c(Y_var, X_var)]
Test_data_regression     <- data.set3[-sample_ids, c(Y_var, X_var)]
} else {
# Splitting training/Testing
Years_dataset <- as.numeric(sort(unique(data.set3$Year)))
Test_years <- c(2015)
Training_years <- setdiff(Years_dataset, Test_years)
Training_data_regression <- dplyr::filter(data.set3, Year %in% Training_years) %>%
dplyr::select_(.dots = c(Y_var, X_var))
Test_data_regression <- dplyr::filter(data.set3, Year %in% Test_years) %>%
dplyr::select_(.dots = c(Y_var, X_var))
}
# Classification data sets -----
Training_data_classification <- Training_data_regression
Training_data_classification$Buy_Sell <- as.factor(ifelse(Training_data_regression[,Y_var] > 0, "Buy", "Sell"))
Training_data_classification <- Training_data_classification[, -which(names(Training_data_classification) == Y_var)]
Test_data_classification <- Test_data_regression
Test_data_classification$Buy_Sell <- as.factor(ifelse(Test_data_regression[,Y_var] > 0, "Buy", "Sell"))
Test_data_classification <- Test_data_classification[, -which(names(Test_data_classification) == Y_var)]
features_information.gain_classification <- information.gain(formula = Buy_Sell ~ ., data = Training_data_classification)
features_gain.ratio_classification <- gain.ratio(formula = Buy_Sell ~ ., data = Training_data_classification)
features_randomForest <- random.forest.importance(formula = Buy_Sell ~ ., data = Training_data_classification, importance.type = 1)
View(features_randomForest)
View(features_gain.ratio_classification)
View(features_information.gain_classification)
install.packages("rmarkdown")
names(Training_data_classification)
head(data.set3)
library(RMySQL)
con <- dbConnect(RMySQL::MySQL(),  default.file = "~/.my.cnf", group = "local_intel")
dbListTables(con)
data.set <- dbReadTable(con, "SharkPositions_good") %>% dplyr::mutate(Date = as.Date(Date))
tbls_list <- dbListTables(con)
counter <- 0
pryr::mem_used()
library(data.table)
library(bit64)
sec_ticker_exchange <- fread("~/R_workspaces/AI_Targetting/Data from Rob/h_security_ticker_exchange.txt", "|")
write.csv(sec_ticker_exchange, "security_ticker_exchange.csv", row.names = FALSE)
tt <- readRDS("security_ticker_exchange.RDS")
library(data.table)
data.table::fwrite(tt, file = "security_ticker_exchange_with_symbols.csv")
View(tt)
tt <- tt[, ReportingDate := as.Date(REPORT_DATE)]
tt$REPORT_DATE <- as.Date(tt$REPORT_DATE)
class(tt$REPORT_DATE)
head(tt)
library(bit64)
head(tt)
library(RMySQL)
con <- dbConnect(RMySQL::MySQL(),  default.file = "~/.my.cnf", group = "local_intel")
dbWriteTable(con, "Inst_Holdings_hist_w_symbols", tt)
dbWriteTable(con, "Inst_Holdings_hist_w_symbols", as.data.frame(tt))
library(readr)
symbol_SIC_Groups <- read_csv("~/R_workspaces/AI_Targetting/Data from Rob/symbolSICGroups.csv")
names(symbol_SIC_Groups)[-1] <- paste0("SIC_", names(symbol_SIC_Groups)[-1])
names(symbol_SIC_Groups)
tt <- dplyr::left_join(tt, symbol_SIC_Groups, by = "Symbol")
tt2 <- dplyr::filter(tt, is.na(SIC_Group1))
NROW(tt2)
View(tt2)
NROW(tt2)/NROW(tt)
tt3 <- dplyr::filter(tt, grepl(pattern = ".", x = Symbol, fixed = TRUE))
View(tt3)
NROW(tt3)
NROW(tt2)
=======
>>>>>>> 2b3418d1753248fd484b43dfc614f72040f4fb2b
>>>>>>> 0c484179b03a9984cb4a73d42a5e6d8bb53378ce
>>>>>>> 24a3fe80a629ed7915a6998dfa68630637e404de
